{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/samithsachidanandan/gaussian-naive-bayes-from-scratch-in-python?scriptVersionId=266655981\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"4114a50f","metadata":{"papermill":{"duration":0.003171,"end_time":"2025-10-08T19:21:41.61438","exception":false,"start_time":"2025-10-08T19:21:41.611209","status":"completed"},"tags":[]},"source":["### Import the necessay Libraries "]},{"cell_type":"code","execution_count":1,"id":"971fcae2","metadata":{"execution":{"iopub.execute_input":"2025-10-08T19:21:41.622356Z","iopub.status.busy":"2025-10-08T19:21:41.622019Z","iopub.status.idle":"2025-10-08T19:21:41.630398Z","shell.execute_reply":"2025-10-08T19:21:41.62926Z"},"papermill":{"duration":0.014375,"end_time":"2025-10-08T19:21:41.632254","exception":false,"start_time":"2025-10-08T19:21:41.617879","status":"completed"},"tags":[]},"outputs":[],"source":["import numpy as np \n","\n"]},{"cell_type":"markdown","id":"65a098ab","metadata":{"papermill":{"duration":0.002282,"end_time":"2025-10-08T19:21:41.637341","exception":false,"start_time":"2025-10-08T19:21:41.635059","status":"completed"},"tags":[]},"source":["### Defining the GaussianNB Class"]},{"cell_type":"code","execution_count":2,"id":"c3ad813e","metadata":{"execution":{"iopub.execute_input":"2025-10-08T19:21:41.644758Z","iopub.status.busy":"2025-10-08T19:21:41.643551Z","iopub.status.idle":"2025-10-08T19:21:41.653602Z","shell.execute_reply":"2025-10-08T19:21:41.652476Z"},"papermill":{"duration":0.015534,"end_time":"2025-10-08T19:21:41.655483","exception":false,"start_time":"2025-10-08T19:21:41.639949","status":"completed"},"tags":[]},"outputs":[],"source":["class GaussianNB:\n","    \n","    def fit(self, X, y):\n","        \n","        X, y = np.asarray(X), np.asarray(y)\n","        self.classes_ = np.unique(y)\n","        n_classes, n_features = len(self.classes_), X.shape[1]\n","\n","        self.means_ = np.zeros((n_classes, n_features))\n","        self.variances_ = np.zeros((n_classes, n_features))\n","        self.priors_ = np.zeros(n_classes) \n","\n","        for idx, k in enumerate(self.classes_):\n","            Xk = X[y == k]\n","\n","            self.means_[idx] = Xk.mean(axis=0)\n","            self.variances_[idx] = Xk.var(axis=0)\n","            self.priors_[idx] = Xk.shape[0] / X.shape[0]\n","        return self\n","\n","    def _log_gaussian(self, X):\n","        num = -0.5 * (X[:, None, : ] - self.means_)**2 /self.variances_\n","        log_prob = num - 0.5 * np.log( 2 * np.pi * self.variances_)\n","\n","        return log_prob.sum(axis =2)\n","\n","    def predict(self, X):\n","        X= np.asarray(X)\n","\n","        log_likelihood = self._log_gaussian(X)\n","        log_prior = np.log(self.priors_)\n","\n","        return self.classes_[np.argmax(log_likelihood + log_prior, axis= 1 )]\n","\n","\n","        \n","        "]},{"cell_type":"markdown","id":"0e09ff3a","metadata":{"papermill":{"duration":0.002844,"end_time":"2025-10-08T19:21:41.661407","exception":false,"start_time":"2025-10-08T19:21:41.658563","status":"completed"},"tags":[]},"source":["#### What is happening in GaussianNB Class\n","\n","In the Fit funtion, First step the data is converted into numpy array the we are identifying all unique class labels then next step we are finding how many unique classes and features are in the data then we are preparing space to store means, variances, and priors for each class/feature once that is done then we are looping over each class and for every class label k  we are selecting all samples withe label k and then stores the mean vector for features of class k, stores the variance vector for features of class k and computes the prior probability of class . Self is returned in the end. "]},{"cell_type":"markdown","id":"19a7d5ab","metadata":{"papermill":{"duration":0.002874,"end_time":"2025-10-08T19:21:41.667275","exception":false,"start_time":"2025-10-08T19:21:41.664401","status":"completed"},"tags":[]},"source":["In the _log_gaussian function, For every sample, calculate the log-probability (log-likelihood) of belonging to each class, using the Gaussian formula.\n","First we are reshaping the input so that each sample can be compared to each class mean (broadcasting) and then computes the square differences between each input sample and class mean, divided by class variance then in the next step applies the rest of the Gaussian log-probability formula for each feature and class. Finally will return the sums the log-probabilities across all features for each sample/class."]},{"cell_type":"markdown","id":"68bdfcab","metadata":{"papermill":{"duration":0.002321,"end_time":"2025-10-08T19:21:41.672681","exception":false,"start_time":"2025-10-08T19:21:41.67036","status":"completed"},"tags":[]},"source":["In the predict function, For a new input, pick the class (from self.classes_) with highest log-probability for each sample. first step is ensuring that the input is a NumPy array then get log-likelihoods (feature-wise probabilities summed for each class/sample) and convert class priors to log-format for easy addition. In the final step, for each sample, add the log-likelihoods for all classes to their respective log-priors and pick the class with the highest sum and returns actual class labels, not just indices.\n","\n","\n"]},{"cell_type":"markdown","id":"1cdc8b3f","metadata":{"papermill":{"duration":0.002605,"end_time":"2025-10-08T19:21:41.677945","exception":false,"start_time":"2025-10-08T19:21:41.67534","status":"completed"},"tags":[]},"source":["### Laoding the Dataset and Libraries from scikit learn"]},{"cell_type":"code","execution_count":3,"id":"09924e44","metadata":{"execution":{"iopub.execute_input":"2025-10-08T19:21:41.685104Z","iopub.status.busy":"2025-10-08T19:21:41.684581Z","iopub.status.idle":"2025-10-08T19:21:43.646284Z","shell.execute_reply":"2025-10-08T19:21:43.64499Z"},"papermill":{"duration":1.967829,"end_time":"2025-10-08T19:21:43.648373","exception":false,"start_time":"2025-10-08T19:21:41.680544","status":"completed"},"tags":[]},"outputs":[],"source":["from sklearn.datasets import load_breast_cancer \n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score "]},{"cell_type":"markdown","id":"a94f30bc","metadata":{"papermill":{"duration":0.00237,"end_time":"2025-10-08T19:21:43.653746","exception":false,"start_time":"2025-10-08T19:21:43.651376","status":"completed"},"tags":[]},"source":["### Train and Test your Model"]},{"cell_type":"code","execution_count":4,"id":"cde30a24","metadata":{"execution":{"iopub.execute_input":"2025-10-08T19:21:43.662791Z","iopub.status.busy":"2025-10-08T19:21:43.661244Z","iopub.status.idle":"2025-10-08T19:21:43.692306Z","shell.execute_reply":"2025-10-08T19:21:43.690824Z"},"papermill":{"duration":0.037559,"end_time":"2025-10-08T19:21:43.694405","exception":false,"start_time":"2025-10-08T19:21:43.656846","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["0.956140350877193\n"]}],"source":["X, y = load_breast_cancer(return_X_y = True)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","\n","clf = GaussianNB().fit(X_train, y_train)\n","\n","y_pred = clf.predict(X_test)\n","\n","print(accuracy_score(y_pred, y_test))"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31153,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"papermill":{"default_parameters":{},"duration":8.106289,"end_time":"2025-10-08T19:21:44.218279","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-10-08T19:21:36.11199","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}