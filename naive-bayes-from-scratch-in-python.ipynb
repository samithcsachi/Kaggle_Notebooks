{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/samithsachidanandan/naive-bayes-from-scratch-in-python?scriptVersionId=270862369\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"e75a6f6b","metadata":{"papermill":{"duration":0.002696,"end_time":"2025-10-25T21:30:59.151478","exception":false,"start_time":"2025-10-25T21:30:59.148782","status":"completed"},"tags":[]},"source":["### Naive Bayes"]},{"cell_type":"markdown","id":"e51fa8f5","metadata":{"papermill":{"duration":0.001931,"end_time":"2025-10-25T21:30:59.156057","exception":false,"start_time":"2025-10-25T21:30:59.154126","status":"completed"},"tags":[]},"source":["Naive Bayes methods are a set of supervised learning algorithms based on applying Bayes’ theorem with the “naive” assumption of conditional independence between every pair of features given the value of the class variable. \n","\n","A naive Bayes model assumes the information about the class provided by each variable is unrelated to the information from the others, with no information shared between the predictors. The highly unrealistic nature of this assumption, called the naive independence assumption, is what gives the classifier its name. These classifiers are some of the simplest Bayesian network models"]},{"cell_type":"markdown","id":"c3a08877","metadata":{"papermill":{"duration":0.001831,"end_time":"2025-10-25T21:30:59.160064","exception":false,"start_time":"2025-10-25T21:30:59.158233","status":"completed"},"tags":[]},"source":["### Importing Library"]},{"cell_type":"code","execution_count":1,"id":"c25a5b74","metadata":{"execution":{"iopub.execute_input":"2025-10-25T21:30:59.165775Z","iopub.status.busy":"2025-10-25T21:30:59.16538Z","iopub.status.idle":"2025-10-25T21:30:59.173083Z","shell.execute_reply":"2025-10-25T21:30:59.172235Z"},"papermill":{"duration":0.012579,"end_time":"2025-10-25T21:30:59.174785","exception":false,"start_time":"2025-10-25T21:30:59.162206","status":"completed"},"tags":[]},"outputs":[],"source":["import numpy as np"]},{"cell_type":"markdown","id":"2de9458b","metadata":{"papermill":{"duration":0.001911,"end_time":"2025-10-25T21:30:59.179291","exception":false,"start_time":"2025-10-25T21:30:59.17738","status":"completed"},"tags":[]},"source":["### Naive Bayes Class"]},{"cell_type":"code","execution_count":2,"id":"971bf265","metadata":{"execution":{"iopub.execute_input":"2025-10-25T21:30:59.184572Z","iopub.status.busy":"2025-10-25T21:30:59.184245Z","iopub.status.idle":"2025-10-25T21:30:59.193637Z","shell.execute_reply":"2025-10-25T21:30:59.192682Z"},"papermill":{"duration":0.01417,"end_time":"2025-10-25T21:30:59.19547","exception":false,"start_time":"2025-10-25T21:30:59.1813","status":"completed"},"tags":[]},"outputs":[],"source":["class NaiveBayes:\n","    def fit(self, X, y):\n","        n_samples, n_features = X.shape\n","        self._classes = np.unique(y)\n","        n_classes = len(self._classes)\n","\n","        # calculate mean, var, and prior for each class\n","        self._mean = np.zeros((n_classes, n_features), dtype=np.float64)\n","        self._var = np.zeros((n_classes, n_features), dtype=np.float64)\n","        self._priors = np.zeros(n_classes, dtype=np.float64)\n","\n","        for idx, c in enumerate(self._classes):\n","            X_c = X[y == c]\n","            self._mean[idx, :] = X_c.mean(axis=0)\n","            self._var[idx, :] = X_c.var(axis=0)\n","            self._priors[idx] = X_c.shape[0] / float(n_samples)\n","\n","    def predict(self, X):\n","        y_pred = [self._predict(x) for x in X]\n","        return np.array(y_pred)\n","\n","    def _predict(self, x):\n","        posteriors = []\n","\n","        # calculate posterior probability for each class\n","        for idx, c in enumerate(self._classes):\n","            prior = np.log(self._priors[idx])\n","            posterior = np.sum(np.log(self._pdf(idx, x)))\n","            posterior = prior + posterior\n","            posteriors.append(posterior)\n","\n","        # return class with highest posterior probability\n","        return self._classes[np.argmax(posteriors)]\n","\n","    def _pdf(self, class_idx, x):\n","        mean = self._mean[class_idx]\n","        var = self._var[class_idx]\n","        numerator = np.exp(-((x - mean) ** 2) / (2 * var))\n","        denominator = np.sqrt(2 * np.pi * var)\n","        return numerator / denominator"]},{"cell_type":"markdown","id":"41cbf3d8","metadata":{"papermill":{"duration":0.002108,"end_time":"2025-10-25T21:30:59.200079","exception":false,"start_time":"2025-10-25T21:30:59.197971","status":"completed"},"tags":[]},"source":["### Testing"]},{"cell_type":"code","execution_count":3,"id":"3da8d92c","metadata":{"execution":{"iopub.execute_input":"2025-10-25T21:30:59.205851Z","iopub.status.busy":"2025-10-25T21:30:59.205551Z","iopub.status.idle":"2025-10-25T21:31:01.077329Z","shell.execute_reply":"2025-10-25T21:31:01.076096Z"},"papermill":{"duration":1.876643,"end_time":"2025-10-25T21:31:01.07897","exception":false,"start_time":"2025-10-25T21:30:59.202327","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Naive Bayes classification accuracy 0.965\n"]}],"source":["\n","if __name__ == \"__main__\":\n","    # Imports\n","    from sklearn.model_selection import train_test_split\n","    from sklearn import datasets\n","\n","    def accuracy(y_true, y_pred):\n","        accuracy = np.sum(y_true == y_pred) / len(y_true)\n","        return accuracy\n","\n","    X, y = datasets.make_classification(\n","        n_samples=1000, n_features=10, n_classes=2, random_state=123\n","    )\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        X, y, test_size=0.2, random_state=123\n","    )\n","\n","    nb = NaiveBayes()\n","    nb.fit(X_train, y_train)\n","    predictions = nb.predict(X_test)\n","\n","    print(\"Naive Bayes classification accuracy\", accuracy(y_test, predictions))"]},{"cell_type":"code","execution_count":null,"id":"773183a4","metadata":{"papermill":{"duration":0.002042,"end_time":"2025-10-25T21:31:01.08354","exception":false,"start_time":"2025-10-25T21:31:01.081498","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"0ed77872","metadata":{"papermill":{"duration":0.002177,"end_time":"2025-10-25T21:31:01.088036","exception":false,"start_time":"2025-10-25T21:31:01.085859","status":"completed"},"tags":[]},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31153,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"papermill":{"default_parameters":{},"duration":7.221828,"end_time":"2025-10-25T21:31:01.611596","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-10-25T21:30:54.389768","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}