{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":125192,"databundleVersionId":15408205,"sourceType":"competition"},{"sourceId":14111592,"sourceType":"datasetVersion","datasetId":8988973}],"dockerImageVersionId":31260,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/samithsachidanandan/predict-heart-disease-catboost-single-model?scriptVersionId=296795395\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Importing Libraries and Loading the Data","metadata":{}},{"cell_type":"code","source":"\n\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats\nfrom sklearn.preprocessing import LabelEncoder\nfrom scipy import stats as scipy_stats\nimport warnings\n\n\nwarnings.filterwarnings(\"ignore\")\nnp.random.seed(42)\n\n\ntrain_file = \"/kaggle/input/playground-series-s6e2/train.csv\"\ntest_file = \"/kaggle/input/playground-series-s6e2/test.csv\"\noriginal_file = \"/kaggle/input/heartdisease/Heart_Disease_Prediction.csv\"\n\ntrain_df = pd.read_csv(train_file)\ntest_df = pd.read_csv(test_file)\noriginal_df = pd.read_csv(original_file)\nsubmission_df = pd.read_csv(\"/kaggle/input/playground-series-s6e2/sample_submission.csv\")\n\nTARGET = \"Heart Disease\"\nID_COL = \"id\"\n\ntrain_df.shape, test_df.shape, original_df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T17:17:39.861452Z","iopub.execute_input":"2026-02-09T17:17:39.862227Z","iopub.status.idle":"2026-02-09T17:17:40.543215Z","shell.execute_reply.started":"2026-02-09T17:17:39.8622Z","shell.execute_reply":"2026-02-09T17:17:40.542618Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"((630000, 15), (270000, 14), (270, 14))"},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"# Base features","metadata":{}},{"cell_type":"code","source":"le = LabelEncoder()\ntrain_df['Heart Disease'] = le.fit_transform(train_df['Heart Disease'])\noriginal_df['Heart Disease'] = le.fit_transform(original_df['Heart Disease'])\n\nbase_features = [col for col in train_df.columns if col not in ['Heart Disease', 'id']] \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T17:17:40.544357Z","iopub.execute_input":"2026-02-09T17:17:40.544606Z","iopub.status.idle":"2026-02-09T17:17:40.649359Z","shell.execute_reply.started":"2026-02-09T17:17:40.54458Z","shell.execute_reply":"2026-02-09T17:17:40.648832Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"train_df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T17:17:40.650117Z","iopub.execute_input":"2026-02-09T17:17:40.650366Z","iopub.status.idle":"2026-02-09T17:17:40.654745Z","shell.execute_reply.started":"2026-02-09T17:17:40.650336Z","shell.execute_reply":"2026-02-09T17:17:40.654188Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(630000, 15)"},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"# Feature Engineering ","metadata":{}},{"cell_type":"code","source":"def preprocess(df):\n    \n    df = df.copy()\n\n    # Acknowledgement https://www.kaggle.com/code/omidbaghchehsaraei/the-best-solo-model-so-far-realmlp-lb-0-95392\n    for col in base_features: \n        if col in original_df.columns:\n           \n            stats_agg = original_df.groupby(col)['Heart Disease'].agg(['mean', 'median', 'std', 'skew', 'count']).reset_index()\n         \n            stats_agg.columns = [col] + [f\"orig_{col}_{s}\" for s in ['mean', 'median', 'std', 'skew', 'count']]\n     \n            df = df.merge(stats_agg, on=col, how='left') \n \n            fill_values = {\n                f\"orig_{col}_mean\": original_df['Heart Disease'].mean(),\n                f\"orig_{col}_median\": original_df['Heart Disease'].median(),\n                f\"orig_{col}_std\": 0,\n                f\"orig_{col}_skew\": 0,\n                f\"orig_{col}_count\": 0\n            }\n            df = df.fillna(value=fill_values)\n \n\n    df['BP_Category'] = pd.cut(df['BP'], \n                               bins=[0, 120, 130, 140, np.inf],\n                               labels=['Normal', 'Elevated', 'Stage1_HTN', 'Stage2_HTN'])\n    \n    df['Cholesterol_Risk'] = pd.cut(df['Cholesterol'],\n                                     bins=[0, 200, 240, np.inf],\n                                     labels=['Desirable', 'Borderline', 'High'])\n    \n\n    df['Pulse_Pressure'] = df['Max HR'] - df['BP']\n    df['MAP'] = (df['BP'] + (2 * (df['Max HR'] * 0.4))) / 3\n    \n    df['BP_Cholesterol_Interaction'] = df['BP'] * df['Cholesterol'] / 1000\n    df['Age_BP_Risk'] = df['Age'] * df['BP'] / 100\n    df['Metabolic_Burden'] = (df['BP'] + df['Cholesterol'] / 100 + df['Max HR'] / 100) / 3\n    \n\n    df['High_BP_High_Chol'] = ((df['BP'] > 140) & (df['Cholesterol'] > 240)).astype(int)\n    df['Age_Risk_Factor'] = (df['Age'] > 50).astype(int) * (df['BP'] > 130).astype(int)\n\n    df['Cholesterol_per_100_BP'] = df['Cholesterol'] / (df['BP'] + 1)\n    df['Age_normalized_HR'] = df['Max HR'] / (df['Age'] + 1)\n    \n\n    df['HR_BP_Ratio'] = df['Max HR'] / (df['BP'] + 1)\n    df['Cardiac_Load_Index'] = (df['Max HR'] * df['BP']) / 10000\n    \n\n    df['FBS_Risk'] = (df['FBS over 120'] == 1).astype(int)\n    \n   \n    df['Age_Squared'] = df['Age'] ** 2\n    df['Age_Cubed'] = df['Age'] ** 3\n    df['BP_Squared'] = df['BP'] ** 2\n\n    numeric_cols = ['Age', 'BP', 'Cholesterol', 'Max HR']\n    for col in numeric_cols:\n        df[f'{col}_ZScore'] = np.abs(scipy_stats.zscore(df[col]))\n    \n\n    df['Abnormal_Count'] = (\n        (df['BP'] > 140).astype(int) +\n        (df['Cholesterol'] > 240).astype(int) +\n        (df['FBS over 120'] == 1).astype(int) +\n        (df['EKG results'] > 0).astype(int) +\n        (df['Exercise angina'] == 1).astype(int) +\n        (df['ST depression'] > 1.0).astype(int)\n    )\n    \n\n    df['Is_Male'] = df['Sex']\n    df['Is_Female'] = 1 - df['Sex']\n    \n\n    chest_pain_severity = {1: 'Typical_Angina', 2: 'Atypical_Angina', \n                          3: 'Non_Anginal_Pain', 4: 'Asymptomatic'}\n    df['Chest pain type_Encoded'] = df['Chest pain type'].map(chest_pain_severity)\n    chest_pain_dummies = pd.get_dummies(df['Chest pain type_Encoded'], prefix='CPT')\n    df = pd.concat([df, chest_pain_dummies], axis=1)\n    \n\n    df['Risk_Profile'] = 'Low'\n    mask_moderate = (df['BP'] > 130) | (df['Cholesterol'] > 200)\n    mask_high = (df['BP'] > 140) & (df['Cholesterol'] > 240)\n    df.loc[mask_moderate, 'Risk_Profile'] = 'Moderate'\n    df.loc[mask_high, 'Risk_Profile'] = 'High'\n    \n    risk_dummies = pd.get_dummies(df['Risk_Profile'], prefix='Risk')\n    df = pd.concat([df, risk_dummies], axis=1)\n\n    df['HR_Reserve'] = 220 - df['Age'] - df['Max HR']\n    df['HR_Reserve_Ratio'] = df['Max HR'] / (220 - df['Age'] + 1)\n    \n\n    df['Cardiac_Efficiency'] = (220 - df['Age']) / (df['Cardiac_Load_Index'] + 1)\n    \n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T17:17:40.655733Z","iopub.execute_input":"2026-02-09T17:17:40.655948Z","iopub.status.idle":"2026-02-09T17:17:40.671364Z","shell.execute_reply.started":"2026-02-09T17:17:40.65593Z","shell.execute_reply":"2026-02-09T17:17:40.670873Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"train_df = preprocess(train_df)\ntest_df = preprocess(test_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T17:17:40.672859Z","iopub.execute_input":"2026-02-09T17:17:40.673131Z","iopub.status.idle":"2026-02-09T17:17:50.370441Z","shell.execute_reply.started":"2026-02-09T17:17:40.673113Z","shell.execute_reply":"2026-02-09T17:17:50.369883Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"# Spliting the Target","metadata":{}},{"cell_type":"code","source":"y_train = train_df['Heart Disease']\nX_train = train_df.drop(['id', 'Heart Disease'], axis=1)\n\nX_test = test_df.copy()\nX_test = X_test.drop('id', axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T17:17:50.371244Z","iopub.execute_input":"2026-02-09T17:17:50.371527Z","iopub.status.idle":"2026-02-09T17:17:50.826347Z","shell.execute_reply.started":"2026-02-09T17:17:50.371482Z","shell.execute_reply":"2026-02-09T17:17:50.82524Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"print(f\"X_train shape: {X_train.shape}\")\nprint(f\"y_train shape: {y_train.shape}\")\nprint(f\"X_test shape: {X_test.shape}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T17:17:50.827591Z","iopub.execute_input":"2026-02-09T17:17:50.827943Z","iopub.status.idle":"2026-02-09T17:17:50.833446Z","shell.execute_reply.started":"2026-02-09T17:17:50.827916Z","shell.execute_reply":"2026-02-09T17:17:50.832717Z"}},"outputs":[{"name":"stdout","text":"X_train shape: (630000, 114)\ny_train shape: (630000,)\nX_test shape: (270000, 114)\n\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"# One - Hot Endcoding ","metadata":{}},{"cell_type":"code","source":"def prepare_data(X_train, X_test):\n    \n    X_train = X_train.copy()\n    X_test = X_test.copy()\n    \n\n    bool_cols = X_train.select_dtypes(include=['bool']).columns.tolist()\n    if bool_cols:\n\n        for col in bool_cols:\n            X_train[col] = X_train[col].astype(int)\n            X_test[col] = X_test[col].astype(int)\n\n\n    category_cols = X_train.select_dtypes(include=['category']).columns.tolist()\n    if category_cols:\n     \n        X_train = pd.get_dummies(X_train, columns=category_cols, prefix=None, drop_first=False)\n        X_test = pd.get_dummies(X_test, columns=category_cols, prefix=None, drop_first=False)\n\n    \n\n    object_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n    if object_cols:\n\n        X_train = pd.get_dummies(X_train, columns=object_cols, prefix=None, drop_first=False)\n        X_test = pd.get_dummies(X_test, columns=object_cols, prefix=None, drop_first=False)\n\n    \n\n    \n    return X_train, X_test\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T17:17:50.834477Z","iopub.execute_input":"2026-02-09T17:17:50.835208Z","iopub.status.idle":"2026-02-09T17:17:50.851569Z","shell.execute_reply.started":"2026-02-09T17:17:50.835176Z","shell.execute_reply":"2026-02-09T17:17:50.850207Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"X_train, X_test = prepare_data(X_train, X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T17:17:50.85272Z","iopub.execute_input":"2026-02-09T17:17:50.853104Z","iopub.status.idle":"2026-02-09T17:17:52.852894Z","shell.execute_reply.started":"2026-02-09T17:17:50.853077Z","shell.execute_reply":"2026-02-09T17:17:52.852291Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"X_train.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T17:17:52.853687Z","iopub.execute_input":"2026-02-09T17:17:52.853878Z","iopub.status.idle":"2026-02-09T17:17:52.863891Z","shell.execute_reply.started":"2026-02-09T17:17:52.853861Z","shell.execute_reply":"2026-02-09T17:17:52.863238Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 630000 entries, 0 to 629999\nColumns: 124 entries, Age to Risk_Profile_Moderate\ndtypes: bool(14), float64(72), int64(38)\nmemory usage: 537.1 MB\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"code","source":"!pip install pytorch-tabnet torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T19:19:46.845586Z","iopub.execute_input":"2026-02-09T19:19:46.845869Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7c1a99b28170>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/pytorch-tabnet/\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score, roc_curve, auc\nfrom catboost import CatBoostClassifier\nfrom pytorch_tabnet.tab_model import TabNetClassifier\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cat_params = {\n    \"objective\": \"Logloss\",\n    \"eval_metric\": \"AUC\",\n    \"iterations\": 8000,  \n    \"learning_rate\": 0.01,  \n    \"depth\": 7, \n    \"subsample\": 0.8,  \n    \"colsample_bylevel\": 0.8, \n    \"l2_leaf_reg\": 3.0,  \n    \"random_state\": 42,\n    \"verbose\": 0,\n    \"thread_count\": -1,\n}\n\ntabnet_params = {\n    \"n_d\": 64,\n    \"n_a\": 64,\n    \"n_steps\": 3,\n    \"gamma\": 1.3,\n    \"lambda_sparse\": 1e-3,\n    \"optimizer_fn\": torch.optim.Adam,\n    \"optimizer_params\": {\"lr\": 2e-2},\n    \"mask_type\": \"softmax\",\n    \"scheduler_params\": {\n        \"step_size\": 10,\n        \"gamma\": 0.9,\n    },\n    \"seed\": 42,\n    \"verbose\": 0,\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n\n\n\nn_splits = 5\nkf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n\n\noof_cat = np.zeros(len(X_train))\noof_tabnet = np.zeros(len(X_train))\noof_ensemble = np.zeros(len(X_train))\n\n\ntest_cat = np.zeros((len(X_test), n_splits))\ntest_tabnet = np.zeros((len(X_test), n_splits))\n\nprint(\"=\" * 80)\nprint(f\"Running {n_splits}-Fold Ensemble (CatBoost + TabNet with Pseudo-Labeling)\")\nprint(\"=\" * 80)\n\nfor fold, (tr_idx, val_idx) in enumerate(kf.split(X_train), 1):\n    X_tr, X_val = X_train.iloc[tr_idx].copy(), X_train.iloc[val_idx].copy()\n    y_tr, y_val = y_train.iloc[tr_idx].copy(), y_train.iloc[val_idx].copy()\n    \n    print(f\"\\n{'=' * 80}\")\n    print(f\"Fold {fold}/{n_splits}\")\n    print(\"=\" * 80)\n    \n\n    print(f\"\\n[{fold}] Training CatBoost...\")\n    cat_model = CatBoostClassifier(**cat_params)\n    cat_model.fit(\n        X_tr, y_tr,\n        eval_set=[(X_val, y_val)],\n        verbose=False,\n    )\n    \n    val_cat = cat_model.predict_proba(X_val)[:, 1]\n    test_cat[:, fold-1] = cat_model.predict_proba(X_test)[:, 1]\n    oof_cat[val_idx] = val_cat\n    roc_auc_cat = roc_auc_score(y_val, val_cat)\n    print(f\"  CatBoost ROC-AUC: {roc_auc_cat:.4f}\")\n    \n\n    print(f\"[{fold}] Training TabNet...\")\n    tabnet_model = TabNetClassifier(**tabnet_params)\n    tabnet_model.fit(\n        X_tr.values, y_tr.values,\n        eval_set=[(X_val.values, y_val.values)],\n        eval_metric=[\"auc\"],\n        max_epochs=200,\n        patience=20,\n        batch_size=256,\n    )\n    \n    val_tabnet = tabnet_model.predict_proba(X_val.values)[:, 1]\n    test_tabnet[:, fold-1] = tabnet_model.predict_proba(X_test.values)[:, 1]\n    oof_tabnet[val_idx] = val_tabnet\n    roc_auc_tabnet = roc_auc_score(y_val, val_tabnet)\n    print(f\"  TabNet ROC-AUC: {roc_auc_tabnet:.4f}\")\n    \n\n    val_ensemble = (val_cat + val_tabnet) / 2\n    oof_ensemble[val_idx] = val_ensemble\n    roc_auc_ensemble = roc_auc_score(y_val, val_ensemble)\n    print(f\"Ensemble ROC-AUC: {roc_auc_ensemble:.4f}\")\n    print(f\"CatBoost: {roc_auc_ensemble - roc_auc_cat:+.4f}\")\n    print(f\"TabNet:   {roc_auc_ensemble - roc_auc_tabnet:+.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\n\" + \"=\" * 80)\nprint(\"Cross-Validation Results (OOF)\")\nprint(\"=\" * 80)\n\ncv_auc_cat = roc_auc_score(y_train, oof_cat)\ncv_auc_tabnet = roc_auc_score(y_train, oof_tabnet)\ncv_auc_ensemble = roc_auc_score(y_train, oof_ensemble)\n\nprint(f\"\\nCatBoost    | ROC-AUC: {cv_auc_cat:.4f}\")\nprint(f\"TabNet      | ROC-AUC: {cv_auc_tabnet:.4f}\")\nprint(f\"Ensemble    | ROC-AUC: {cv_auc_ensemble:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\n\" + \"=\" * 80)\nprint(\"Training final models on full training set...\")\nprint(\"=\" * 80)\n\nfinal_cat = CatBoostClassifier(**cat_params)\nfinal_cat.fit(X_train, y_train, verbose=False)\ny_test_cat_final = final_cat.predict_proba(X_test)[:, 1]\nprint(\"CatBoost final model trained\")\n\nfinal_tabnet = TabNetClassifier(**tabnet_params)\nfinal_tabnet.fit(\n    X_train.values, y_train.values,\n    max_epochs=200,\n    patience=20,\n    batch_size=256,\n)\ny_test_tabnet_final = final_tabnet.predict_proba(X_test.values)[:, 1]\nprint(\"TabNet final model trained\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_test_cat_avg = test_cat.mean(axis=1)\ny_test_tabnet_avg = test_tabnet.mean(axis=1)\ny_test_ensemble_fold = (y_test_cat_avg + y_test_tabnet_avg) / 2\n\n\ny_test_ensemble_final = (y_test_cat_final + y_test_tabnet_final) / 2\n\ny_test_final = (y_test_ensemble_fold + y_test_ensemble_final) / 2\nprint(f\"y_test_final shape: {y_test_final.shape}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Submission ","metadata":{}},{"cell_type":"code","source":"submission = submission_df.copy()\nsubmission[\"Heart Disease\"] = y_test_final\n\nsubmission.to_csv('submission.csv', index=False)\nprint(\"\\n Submission saved to 'submission.csv'\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Acknowledgement https://www.kaggle.com/code/omidbaghchehsaraei/the-best-solo-model-so-far-realmlp-lb-0-95392","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}