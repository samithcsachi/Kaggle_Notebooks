{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":119082,"databundleVersionId":14993753,"sourceType":"competition"},{"sourceId":13904981,"sourceType":"datasetVersion","datasetId":8762382}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Acknowledgement: \n\n[https://www.kaggle.com/code/mdevian/ps-s6e1-clean-strong-baseline-ridge-xgb-fe](https://www.kaggle.com/code/mdevian/ps-s6e1-clean-strong-baseline-ridge-xgb-fe)\n[https://www.kaggle.com/code/act18l/s6e1-single-xgb-add-categorymean](https://www.kaggle.com/code/act18l/s6e1-single-xgb-add-categorymean)","metadata":{}},{"cell_type":"markdown","source":"### Importing Libraries and Loading the Data ","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, root_mean_squared_error, mean_absolute_error\nfrom sklearn.model_selection import StratifiedKFold\nimport xgboost as xgb\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import TargetEncoder, StandardScaler\nfrom sklearn.base import BaseEstimator, TransformerMixin\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\nnp.random.seed(42)\n\n# Load data\ntrain_file = \"/kaggle/input/playground-series-s6e1/train.csv\"\ntest_file = \"/kaggle/input/playground-series-s6e1/test.csv\"\noriginal_file = \"/kaggle/input/exam-score-prediction-dataset/Exam_Score_Prediction.csv\"\n\ntrain_df = pd.read_csv(train_file)\ntest_df = pd.read_csv(test_file)\noriginal_df = pd.read_csv(original_file)\nsubmission_df = pd.read_csv(\"/kaggle/input/playground-series-s6e1/sample_submission.csv\")\n\nTARGET = \"exam_score\"\nID_COL = \"id\"\n\ntrain_df.shape, test_df.shape, original_df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T08:20:44.465572Z","iopub.execute_input":"2026-01-07T08:20:44.465841Z","iopub.status.idle":"2026-01-07T08:20:49.192031Z","shell.execute_reply.started":"2026-01-07T08:20:44.465809Z","shell.execute_reply":"2026-01-07T08:20:49.191402Z"}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"((630000, 13), (270000, 12), (20000, 13))"},"metadata":{}}],"execution_count":1},{"cell_type":"markdown","source":"### Base features","metadata":{}},{"cell_type":"code","source":"base_features = [col for col in train_df.columns if col not in [TARGET, ID_COL]]\n\n\nCATS = train_df.select_dtypes(\"object\").columns.to_list()\nprint(\"CATS:\", CATS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T08:20:49.193481Z","iopub.execute_input":"2026-01-07T08:20:49.193688Z","iopub.status.idle":"2026-01-07T08:20:49.247396Z","shell.execute_reply.started":"2026-01-07T08:20:49.193668Z","shell.execute_reply":"2026-01-07T08:20:49.246635Z"}},"outputs":[{"name":"stdout","text":"CATS: ['gender', 'course', 'internet_access', 'sleep_quality', 'study_method', 'facility_rating', 'exam_difficulty']\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### Feature Engineering","metadata":{}},{"cell_type":"code","source":"\n\nclass CategoryMeanTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self, cat_cols=None):\n        self.cat_cols = cat_cols\n        self.mappings_ = {}\n    \n    def fit(self, X, y):\n        X = X.copy()\n        if self.cat_cols is None:\n            self.cat_cols = X.select_dtypes(include=['category', 'object']).columns.tolist()\n        self.mappings_ = {}\n        for col in self.cat_cols:\n            df_temp = pd.DataFrame({col: X[col], 'y': y})\n            group_means = df_temp.groupby(col, dropna=False)['y'].mean()\n            sorted_categories = group_means.sort_values().index\n            self.mappings_[col] = {cat: i for i, cat in enumerate(sorted_categories)}\n        return self\n\n    def transform(self, X, y=None):\n        X = X.copy()\n        for col, mapping in self.mappings_.items():\n            if col in X.columns:\n                X[col] = X[col].map(mapping).astype(np.float32)\n        return X","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T08:20:49.248440Z","iopub.execute_input":"2026-01-07T08:20:49.248757Z","iopub.status.idle":"2026-01-07T08:20:49.255639Z","shell.execute_reply.started":"2026-01-07T08:20:49.248725Z","shell.execute_reply":"2026-01-07T08:20:49.254761Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def preprocess(df):\n\n    df_temp = df.copy()\n    eps = 1e-5\n    \n\n    sh_pos = df_temp['study_hours'].clip(lower=0)\n    ca_pos = df_temp['class_attendance'].clip(lower=0)\n    sl_pos = df_temp['sleep_hours'].clip(lower=0)\n    ag_pos = df_temp['age'].clip(lower=0)\n    \n \n    df_temp['study_hours_squared'] = sh_pos ** 2\n    df_temp['study_hours_cubed'] = sh_pos ** 3\n    df_temp['study_hours_quartic'] = sh_pos ** 4\n    df_temp['study_hours_5th'] = sh_pos ** 5\n    \n    df_temp['class_attendance_squared'] = ca_pos ** 2\n    df_temp['class_attendance_cubed'] = ca_pos ** 3\n    df_temp['class_attendance_quartic'] = ca_pos ** 4\n    \n    df_temp['sleep_hours_squared'] = sl_pos ** 2\n    df_temp['sleep_hours_cubed'] = sl_pos ** 3\n    df_temp['sleep_hours_quartic'] = sl_pos ** 4\n    \n    df_temp['age_squared'] = ag_pos ** 2\n    df_temp['age_cubed'] = ag_pos ** 3\n    df_temp['age_quartic'] = ag_pos ** 4\n    \n \n    df_temp['log_study_hours'] = np.log1p(sh_pos)\n    df_temp['log_class_attendance'] = np.log1p(ca_pos)\n    df_temp['log_sleep_hours'] = np.log1p(sl_pos)\n    df_temp['log_age'] = np.log1p(ag_pos)\n    df_temp['log1p_study_hours'] = np.log1p(sh_pos + 1)\n    df_temp['log2_study_hours'] = np.log2(sh_pos + 1)\n    df_temp['log_study_hours_squared'] = (np.log1p(sh_pos)) ** 2\n    \n\n    df_temp['sqrt_study_hours'] = np.sqrt(sh_pos)\n    df_temp['sqrt_class_attendance'] = np.sqrt(ca_pos)\n    df_temp['sqrt_sleep_hours'] = np.sqrt(sl_pos)\n    df_temp['sqrt_age'] = np.sqrt(ag_pos)\n    \n    df_temp['cbrt_study_hours'] = np.cbrt(sh_pos)\n    df_temp['cbrt_class_attendance'] = np.cbrt(ca_pos)\n    df_temp['cbrt_sleep_hours'] = np.cbrt(sl_pos)\n    \n    df_temp['power_study_15'] = sh_pos ** 1.5\n    df_temp['power_attendance_15'] = ca_pos ** 1.5\n    df_temp['power_sleep_15'] = sl_pos ** 1.5\n    \n    df_temp['power_study_025'] = sh_pos ** 0.25\n    df_temp['power_attendance_025'] = ca_pos ** 0.25\n    \n\n    df_temp['inv_sleep'] = 1.0 / (sl_pos + 1.0)\n    df_temp['inv_study'] = 1.0 / (sh_pos + 1.0)\n    df_temp['inv_attendance'] = 1.0 / (ca_pos + 1.0)\n    df_temp['inv_age'] = 1.0 / (ag_pos + 1.0)\n    \n    df_temp['inv_sqrt_study'] = 1.0 / (np.sqrt(sh_pos) + eps)\n    df_temp['inv_sqrt_attendance'] = 1.0 / (np.sqrt(ca_pos) + eps)\n    \n\n    df_temp['study_tanh'] = np.tanh(sh_pos / 10.0)\n    df_temp['sleep_tanh'] = np.tanh(sl_pos / 10.0)\n    df_temp['attendance_tanh'] = np.tanh(ca_pos / 100.0)\n    df_temp['age_tanh'] = np.tanh(ag_pos / 25.0)\n    \n    df_temp['study_sigmoid'] = 1.0 / (1.0 + np.exp(-(sh_pos - 5.0)))\n    df_temp['sleep_sigmoid'] = 1.0 / (1.0 + np.exp(-(sl_pos - 7.0)))\n    df_temp['attendance_sigmoid'] = 1.0 / (1.0 + np.exp(-(ca_pos - 85.0) / 8.0))\n    df_temp['age_sigmoid'] = 1.0 / (1.0 + np.exp(-(ag_pos - 20.0) / 3.0))\n    \n    df_temp['study_elu'] = np.where(sh_pos > 0, sh_pos, 0.5 * (np.exp(sh_pos) - 1))\n    df_temp['sleep_elu'] = np.where(sl_pos > 0, sl_pos, 0.5 * (np.exp(sl_pos) - 1))\n    \n    df_temp['study_relu'] = np.maximum(0, sh_pos)\n    df_temp['sleep_relu'] = np.maximum(0, sl_pos)\n    df_temp['attendance_relu'] = np.maximum(0, ca_pos)\n    \n\n    df_temp['study_x_attendance'] = sh_pos * ca_pos\n    df_temp['study_x_sleep'] = sh_pos * sl_pos\n    df_temp['attendance_x_sleep'] = ca_pos * sl_pos\n    df_temp['study_x_age'] = sh_pos * ag_pos\n    df_temp['attendance_x_age'] = ca_pos * ag_pos\n    df_temp['sleep_x_age'] = sl_pos * ag_pos\n    \n\n    df_temp['study_sq_x_attendance'] = (sh_pos ** 2) * ca_pos\n    df_temp['study_x_attendance_sq'] = sh_pos * (ca_pos ** 2)\n    df_temp['study_sq_x_attendance_sq'] = (sh_pos ** 2) * (ca_pos ** 2)\n    \n    df_temp['sleep_sq_x_attendance'] = (sl_pos ** 2) * ca_pos\n    df_temp['study_sq_x_sleep'] = (sh_pos ** 2) * sl_pos\n    df_temp['study_x_sleep_sq'] = sh_pos * (sl_pos ** 2)\n    \n\n    df_temp['study_x_attendance_x_sleep'] = sh_pos * ca_pos * sl_pos\n    df_temp['study_sq_x_attendance_x_sleep'] = (sh_pos ** 2) * ca_pos * sl_pos\n    df_temp['study_x_attendance_sq_x_sleep'] = sh_pos * (ca_pos ** 2) * sl_pos\n    df_temp['study_x_attendance_x_sleep_sq'] = sh_pos * ca_pos * (sl_pos ** 2)\n    \n    df_temp['study_x_attendance_x_age'] = sh_pos * ca_pos * ag_pos\n    df_temp['study_x_sleep_x_age'] = sh_pos * sl_pos * ag_pos\n    df_temp['attendance_x_sleep_x_age'] = ca_pos * sl_pos * ag_pos\n    \n\n    study_mean = sh_pos.mean()\n    sleep_mean = sl_pos.mean()\n    att_mean = ca_pos.mean()\n    age_mean = ag_pos.mean()\n    \n    df_temp['study_center_5'] = sh_pos - 5.0\n    df_temp['sleep_center_7'] = sl_pos - 7.0\n    df_temp['att_center_85'] = ca_pos - 85.0\n    df_temp['age_center_mean'] = ag_pos - age_mean\n    \n    df_temp['study_center_sq'] = (sh_pos - 5.0) ** 2\n    df_temp['sleep_center_sq'] = (sl_pos - 7.0) ** 2\n    df_temp['att_center_sq'] = (ca_pos - 85.0) ** 2\n    \n    df_temp['study_center_cubed'] = (sh_pos - 5.0) ** 3\n    df_temp['sleep_center_cubed'] = (sl_pos - 7.0) ** 3\n    df_temp['att_center_cubed'] = (ca_pos - 85.0) ** 3\n    \n\n    df_temp['study_over_sleep'] = sh_pos / (sl_pos + eps)\n    df_temp['attendance_over_sleep'] = ca_pos / (sl_pos + eps)\n    df_temp['attendance_over_study'] = ca_pos / (sh_pos + eps)\n    df_temp['sleep_over_study'] = sl_pos / (sh_pos + eps)\n    df_temp['study_over_age'] = sh_pos / (ag_pos + eps)\n    df_temp['attendance_over_age'] = ca_pos / (ag_pos + eps)\n    \n\n    df_temp['log_study_sleep_ratio'] = np.log1p(sh_pos) / (np.log1p(sl_pos) + eps)\n    df_temp['log_att_study_ratio'] = np.log1p(ca_pos) / (np.log1p(sh_pos) + eps)\n    df_temp['sqrt_study_attendance_ratio'] = np.sqrt(sh_pos) / (np.sqrt(ca_pos) + eps)\n    \n    df_temp['study_efficiency'] = (sh_pos * ca_pos) / (sl_pos + 1)\n    df_temp['study_efficiency_log'] = np.log1p((sh_pos * ca_pos) / (sl_pos + 1))\n    \n    df_temp['balanced_effort'] = (sh_pos + ca_pos + sl_pos) / 3.0\n    df_temp['effort_variance'] = np.sqrt(((sh_pos - study_mean) ** 2 + \n                                          (ca_pos - att_mean) ** 2 + \n                                          (sl_pos - sleep_mean) ** 2) / 3.0)\n    \n\n    df_temp['study_hours_clip_12'] = sh_pos.clip(0, 12)\n    df_temp['sleep_hours_clip_12'] = sl_pos.clip(0, 12)\n    df_temp['attendance_clip_100'] = ca_pos.clip(0, 100)\n    df_temp['age_clip_30'] = ag_pos.clip(0, 30)\n    \n    df_temp['study_bounded'] = np.maximum(0, np.minimum(12, sh_pos))\n    df_temp['sleep_bounded'] = np.maximum(0, np.minimum(12, sl_pos))\n    \n\n    df_temp['sleep_gap_8'] = np.abs(sl_pos - 8.0)\n    df_temp['sleep_gap_7'] = np.abs(sl_pos - 7.0)\n    df_temp['sleep_gap_min'] = np.minimum(np.abs(sl_pos - 7.0), np.abs(sl_pos - 8.0))\n    \n    df_temp['attendance_gap_100'] = np.abs(ca_pos - 100.0)\n    df_temp['attendance_gap_90'] = np.abs(ca_pos - 90.0)\n    df_temp['attendance_gap_85'] = np.abs(ca_pos - 85.0)\n    df_temp['attendance_gap_min'] = np.minimum(np.minimum(np.abs(ca_pos - 100.0), np.abs(ca_pos - 90.0)), \n                                                np.abs(ca_pos - 85.0))\n    \n    df_temp['study_gap_6'] = np.abs(sh_pos - 6.0)\n    df_temp['study_gap_8'] = np.abs(sh_pos - 8.0)\n    df_temp['study_gap_min'] = np.minimum(np.abs(sh_pos - 6.0), np.abs(sh_pos - 8.0))\n    \n    df_temp['age_gap_20'] = np.abs(ag_pos - 20.0)\n    \n\n    df_temp['age_bin_num'] = pd.cut(df_temp['age'], bins=[0, 17, 19, 21, 23, 100], \n                                     labels=[0, 1, 2, 3, 4]).astype(float)\n    df_temp['study_bin_num'] = pd.cut(df_temp['study_hours'], bins=[-1, 2, 4, 6, 8, 100], \n                                       labels=[0, 1, 2, 3, 4]).astype(float)\n    df_temp['sleep_bin_num'] = pd.cut(df_temp['sleep_hours'], bins=[-1, 5, 6, 7, 8, 100], \n                                       labels=[0, 1, 2, 3, 4]).astype(float)\n    df_temp['attendance_bin_num'] = pd.cut(df_temp['class_attendance'], \n                                            bins=[-1, 60, 75, 85, 95, 101], \n                                            labels=[0, 1, 2, 3, 4]).astype(float)\n    \n\n    df_temp['study_bin_fine'] = pd.cut(df_temp['study_hours'], bins=[-1, 1, 2, 3, 4, 5, 6, 7, 8, 100], \n                                        labels=list(range(9))).astype(float)\n    df_temp['attendance_bin_fine'] = pd.cut(df_temp['class_attendance'], \n                                             bins=[-1, 50, 60, 70, 80, 85, 90, 95, 100, 101], \n                                             labels=list(range(9))).astype(float)\n    \n\n    sleep_quality_map = {'poor': 0, 'average': 1, 'good': 2}\n    facility_rating_map = {'low': 0, 'medium': 1, 'high': 2}\n    exam_difficulty_map = {'easy': 0, 'moderate': 1, 'hard': 2}\n    gender_map = {'male': 0, 'female': 1}\n    internet_access_map = {'no': 0, 'yes': 1}\n    \n    df_temp['sleep_quality_numeric'] = df_temp['sleep_quality'].map(sleep_quality_map).fillna(1).astype(int)\n    df_temp['facility_rating_numeric'] = df_temp['facility_rating'].map(facility_rating_map).fillna(1).astype(int)\n    df_temp['exam_difficulty_numeric'] = df_temp['exam_difficulty'].map(exam_difficulty_map).fillna(1).astype(int)\n    df_temp['gender_numeric'] = df_temp['gender'].map(gender_map).fillna(0).astype(int) if 'gender' in df_temp.columns else 0\n    df_temp['internet_access_numeric'] = df_temp['internet_access'].map(internet_access_map).fillna(0).astype(int) if 'internet_access' in df_temp.columns else 0\n    \n    if 'study_method' in df_temp.columns:\n        study_methods = df_temp['study_method'].unique()\n        study_method_map = {method: i for i, method in enumerate(sorted(study_methods))}\n        df_temp['study_method_numeric'] = df_temp['study_method'].map(study_method_map).fillna(0).astype(int)\n    else:\n        df_temp['study_method_numeric'] = 0\n    \n    if 'course' in df_temp.columns:\n        courses = df_temp['course'].unique()\n        course_map = {course: i for i, course in enumerate(sorted(courses))}\n        df_temp['course_numeric'] = df_temp['course'].map(course_map).fillna(0).astype(int)\n    else:\n        df_temp['course_numeric'] = 0\n    \n\n    df_temp['study_x_sleep_quality'] = sh_pos * df_temp['sleep_quality_numeric']\n    df_temp['attendance_x_facility'] = ca_pos * df_temp['facility_rating_numeric']\n    df_temp['sleep_x_difficulty'] = sl_pos * df_temp['exam_difficulty_numeric']\n    df_temp['study_x_internet'] = sh_pos * df_temp['internet_access_numeric']\n    df_temp['attendance_x_internet'] = ca_pos * df_temp['internet_access_numeric']\n    \n    df_temp['facility_x_sleepq'] = df_temp['facility_rating_numeric'] * df_temp['sleep_quality_numeric']\n    df_temp['difficulty_x_facility'] = df_temp['exam_difficulty_numeric'] * df_temp['facility_rating_numeric']\n    df_temp['difficulty_x_sleepq'] = df_temp['exam_difficulty_numeric'] * df_temp['sleep_quality_numeric']\n    \n    df_temp['study_method_x_internet'] = df_temp['study_method_numeric'] * df_temp['internet_access_numeric']\n    df_temp['course_x_difficulty'] = df_temp['course_numeric'] * df_temp['exam_difficulty_numeric']\n    \n\n    df_temp['high_att_low_sleep'] = ((ca_pos >= 90) & (sl_pos <= 6)).astype(int)\n    df_temp['high_att_high_study'] = ((ca_pos >= 90) & (sh_pos >= 6)).astype(int)\n    df_temp['low_att_high_study'] = ((ca_pos <= 60) & (sh_pos >= 7)).astype(int)\n    df_temp['ideal_sleep_flag'] = ((sl_pos >= 7) & (sl_pos <= 9)).astype(int)\n    df_temp['short_sleep_flag'] = (sl_pos <= 5.5).astype(int)\n    df_temp['long_study_flag'] = (sh_pos >= 7).astype(int)\n    df_temp['perfect_attendance'] = (ca_pos >= 95).astype(int)\n    df_temp['low_attendance'] = (ca_pos <= 60).astype(int)\n    \n    df_temp['good_facility'] = (df_temp['facility_rating_numeric'] >= 1).astype(int)\n    df_temp['hard_exam'] = (df_temp['exam_difficulty_numeric'] >= 2).astype(int)\n    df_temp['poor_sleep_quality'] = (df_temp['sleep_quality_numeric'] <= 1).astype(int)\n    df_temp['has_internet'] = (df_temp['internet_access_numeric'] == 1).astype(int)\n    \n\n    df_temp['efficiency'] = (sh_pos * ca_pos) / (sl_pos + 1)\n    df_temp['efficiency2'] = (df_temp['study_hours_clip_12'] * df_temp['attendance_clip_100']) / (df_temp['sleep_hours_clip_12'] + 1)\n    df_temp['efficiency_normalized'] = (sh_pos / 8.0) * (ca_pos / 100.0) * (sl_pos / 8.0)\n    \n    df_temp['weighted_effort'] = (0.06 * ca_pos + 2.0 * sh_pos + 1.2 * sl_pos)\n    df_temp['weighted_effort_x_difficulty'] = df_temp['weighted_effort'] * (1.0 + 0.2 * df_temp['exam_difficulty_numeric'])\n    \n\n    df_temp['harmonic_effort'] = 3 / ((1 / (sh_pos + eps)) + (1 / (ca_pos + eps)) + (1 / (sl_pos + eps)))\n    \n\n    df_temp['geo_effort'] = ((sh_pos + 1) * (ca_pos + 1) * (sl_pos + 1)) ** (1 / 3)\n    \n\n    df_temp['power_mean_effort'] = ((sh_pos ** 2 + ca_pos ** 2 + sl_pos ** 2) / 3.0) ** 0.5\n    \n\n    df_temp['study_rank'] = sh_pos.rank(pct=True)\n    df_temp['attendance_rank'] = ca_pos.rank(pct=True)\n    df_temp['sleep_rank'] = sl_pos.rank(pct=True)\n    df_temp['age_rank'] = ag_pos.rank(pct=True)\n    \n    df_temp['study_z'] = (sh_pos - study_mean) / (sh_pos.std() + eps)\n    df_temp['attendance_z'] = (ca_pos - att_mean) / (ca_pos.std() + eps)\n    df_temp['sleep_z'] = (sl_pos - sleep_mean) / (sl_pos.std() + eps)\n    df_temp['age_z'] = (ag_pos - age_mean) / (ag_pos.std() + eps)\n    \n \n    study_q75 = sh_pos.quantile(0.75)\n    att_q75 = ca_pos.quantile(0.75)\n    \n    df_temp['study_above_q75'] = (sh_pos >= study_q75).astype(int)\n    df_temp['attendance_above_q75'] = (ca_pos >= att_q75).astype(int)\n    \n \n    df_temp['study_above_6'] = np.maximum(0, sh_pos - 6)\n    df_temp['study_above_8'] = np.maximum(0, sh_pos - 8)\n    df_temp['sleep_below_6'] = np.maximum(0, 6 - sl_pos)\n    df_temp['sleep_below_5'] = np.maximum(0, 5 - sl_pos)\n    df_temp['attendance_below_75'] = np.maximum(0, 75 - ca_pos)\n    df_temp['attendance_below_85'] = np.maximum(0, 85 - ca_pos)\n    \n    df_temp['study_excess'] = np.maximum(0, sh_pos - 8)\n    df_temp['sleep_excess'] = np.maximum(0, sl_pos - 9)\n    \n\n    df_temp['high_study_good_facility'] = (sh_pos >= 6) & (df_temp['facility_rating_numeric'] >= 1)\n    df_temp['high_study_good_sleep'] = (sh_pos >= 6) & (df_temp['sleep_quality_numeric'] >= 1)\n    df_temp['high_att_good_sleep'] = (ca_pos >= 85) & (df_temp['sleep_quality_numeric'] >= 1)\n    \n    df_temp['low_study_easy_exam'] = (sh_pos <= 3) & (df_temp['exam_difficulty_numeric'] == 0)\n    df_temp['high_study_hard_exam'] = (sh_pos >= 7) & (df_temp['exam_difficulty_numeric'] == 2)\n    \n\n    df_temp['study_hours_log_log'] = np.log1p(np.log1p(sh_pos))\n    df_temp['attendance_log_log'] = np.log1p(np.log1p(ca_pos))\n    \n\n    ideal_study = 6.0\n    ideal_sleep = 8.0\n    ideal_attendance = 90.0\n    \n    df_temp['study_distance_from_ideal'] = np.abs(sh_pos - ideal_study)\n    df_temp['sleep_distance_from_ideal'] = np.abs(sl_pos - ideal_sleep)\n    df_temp['attendance_distance_from_ideal'] = np.abs(ca_pos - ideal_attendance)\n    \n    df_temp['total_distance_from_ideal'] = (\n        df_temp['study_distance_from_ideal'] + \n        df_temp['sleep_distance_from_ideal'] + \n        df_temp['attendance_distance_from_ideal'] / 10\n    )\n    \n    df_temp['euclidean_distance'] = np.sqrt(\n        (sh_pos - ideal_study) ** 2 + \n        (sl_pos - ideal_sleep) ** 2 + \n        ((ca_pos - ideal_attendance) / 10) ** 2\n    )\n    \n\n    numeric_features = [\n        \n        'study_hours_squared', 'study_hours_cubed', 'study_hours_quartic', 'study_hours_5th',\n        'class_attendance_squared', 'class_attendance_cubed', 'class_attendance_quartic',\n        'sleep_hours_squared', 'sleep_hours_cubed', 'sleep_hours_quartic',\n        'age_squared', 'age_cubed', 'age_quartic',\n        \n  \n        'log_study_hours', 'log_class_attendance', 'log_sleep_hours', 'log_age',\n        'log1p_study_hours', 'log2_study_hours', 'log_study_hours_squared',\n        \n       \n        'sqrt_study_hours', 'sqrt_class_attendance', 'sqrt_sleep_hours', 'sqrt_age',\n        'cbrt_study_hours', 'cbrt_class_attendance', 'cbrt_sleep_hours',\n        'power_study_15', 'power_attendance_15', 'power_sleep_15',\n        'power_study_025', 'power_attendance_025',\n        \n\n        'inv_sleep', 'inv_study', 'inv_attendance', 'inv_age',\n        'inv_sqrt_study', 'inv_sqrt_attendance',\n        \n  \n        'study_tanh', 'sleep_tanh', 'attendance_tanh', 'age_tanh',\n        'study_sigmoid', 'sleep_sigmoid', 'attendance_sigmoid', 'age_sigmoid',\n        'study_elu', 'sleep_elu',\n        'study_relu', 'sleep_relu', 'attendance_relu',\n        \n\n        'study_x_attendance', 'study_x_sleep', 'attendance_x_sleep',\n        'study_x_age', 'attendance_x_age', 'sleep_x_age',\n        'study_sq_x_attendance', 'study_x_attendance_sq', 'study_sq_x_attendance_sq',\n        'sleep_sq_x_attendance', 'study_sq_x_sleep', 'study_x_sleep_sq',\n        \n\n        'study_x_attendance_x_sleep', 'study_sq_x_attendance_x_sleep',\n        'study_x_attendance_sq_x_sleep', 'study_x_attendance_x_sleep_sq',\n        'study_x_attendance_x_age', 'study_x_sleep_x_age', 'attendance_x_sleep_x_age',\n        \n  \n        'study_center_5', 'sleep_center_7', 'att_center_85', 'age_center_mean',\n        'study_center_sq', 'sleep_center_sq', 'att_center_sq',\n        'study_center_cubed', 'sleep_center_cubed', 'att_center_cubed',\n        \n\n        'study_over_sleep', 'attendance_over_sleep', 'attendance_over_study',\n        'sleep_over_study', 'study_over_age', 'attendance_over_age',\n        'log_study_sleep_ratio', 'log_att_study_ratio', 'sqrt_study_attendance_ratio',\n        'study_efficiency', 'study_efficiency_log',\n        'balanced_effort', 'effort_variance',\n        \n    \n        'study_hours_clip_12', 'sleep_hours_clip_12', 'attendance_clip_100', 'age_clip_30',\n        'study_bounded', 'sleep_bounded',\n        \n       \n        'sleep_gap_8', 'sleep_gap_7', 'sleep_gap_min',\n        'attendance_gap_100', 'attendance_gap_90', 'attendance_gap_85', 'attendance_gap_min',\n        'study_gap_6', 'study_gap_8', 'study_gap_min', 'age_gap_20',\n        \n     \n        'age_bin_num', 'study_bin_num', 'sleep_bin_num', 'attendance_bin_num',\n        'study_bin_fine', 'attendance_bin_fine',\n        \n     \n        'sleep_quality_numeric', 'facility_rating_numeric', 'exam_difficulty_numeric',\n        'gender_numeric', 'internet_access_numeric', 'study_method_numeric', 'course_numeric',\n        \n   \n        'study_x_sleep_quality', 'attendance_x_facility', 'sleep_x_difficulty',\n        'study_x_internet', 'attendance_x_internet',\n        'facility_x_sleepq', 'difficulty_x_facility', 'difficulty_x_sleepq',\n        'study_method_x_internet', 'course_x_difficulty',\n        \n  \n        'high_att_low_sleep', 'high_att_high_study', 'low_att_high_study',\n        'ideal_sleep_flag', 'short_sleep_flag', 'long_study_flag',\n        'perfect_attendance', 'low_attendance',\n        'good_facility', 'hard_exam', 'poor_sleep_quality', 'has_internet',\n        \n\n        'efficiency', 'efficiency2', 'efficiency_normalized',\n        'weighted_effort', 'weighted_effort_x_difficulty',\n        'harmonic_effort', 'geo_effort', 'power_mean_effort',\n        \n \n        'study_rank', 'attendance_rank', 'sleep_rank', 'age_rank',\n        'study_z', 'attendance_z', 'sleep_z', 'age_z',\n        'study_above_q75', 'attendance_above_q75',\n        \n  \n        'study_above_6', 'study_above_8', 'sleep_below_6', 'sleep_below_5',\n        'attendance_below_75', 'attendance_below_85',\n        'study_excess', 'sleep_excess',\n        \n   \n        'high_study_good_facility', 'high_study_good_sleep', 'high_att_good_sleep',\n        'low_study_easy_exam', 'high_study_hard_exam',\n        \n      \n        'study_hours_log_log', 'attendance_log_log',\n        \n   \n        'study_distance_from_ideal', 'sleep_distance_from_ideal', 'attendance_distance_from_ideal',\n        'total_distance_from_ideal', 'euclidean_distance',\n    ]\n    \n    return df_temp[base_features + numeric_features], numeric_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T08:20:49.256681Z","iopub.execute_input":"2026-01-07T08:20:49.256953Z","iopub.status.idle":"2026-01-07T08:20:49.318911Z","shell.execute_reply.started":"2026-01-07T08:20:49.256933Z","shell.execute_reply":"2026-01-07T08:20:49.318244Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### Preprocessing and Preparing the Data","metadata":{}},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*50)\nprint(\"PREPROCESSING DATA\")\nprint(\"=\"*50)\n\n\nX_raw, numeric_cols = preprocess(train_df)\ny = train_df[TARGET].reset_index(drop=True)\n\nX_test_raw, _ = preprocess(test_df)\nX_orig_raw, _ = preprocess(original_df)\ny_orig = original_df[TARGET].reset_index(drop=True)\n\n\ny = y.clip(0, 100)\ny_orig = y_orig.clip(0, 100)\n\nfull_data = pd.concat([X_raw, X_test_raw, X_orig_raw], axis=0, ignore_index=True)\n\n\nfor col in numeric_cols:\n    full_data[col] = full_data[col].astype(float)\n\n\nX = full_data.iloc[:len(train_df)].copy()\nX_test = full_data.iloc[len(train_df):len(train_df) + len(test_df)].copy()\nX_original = full_data.iloc[len(train_df) + len(test_df):].copy()\n\nprint(f\"Feature shapes - X: {X.shape}, X_test: {X_test.shape}, X_original: {X_original.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T08:20:49.320746Z","iopub.execute_input":"2026-01-07T08:20:49.321034Z","iopub.status.idle":"2026-01-07T08:20:55.430286Z","shell.execute_reply.started":"2026-01-07T08:20:49.321012Z","shell.execute_reply":"2026-01-07T08:20:55.429628Z"}},"outputs":[{"name":"stdout","text":"\n==================================================\nPREPROCESSING DATA\n==================================================\nFeature shapes - X: (630000, 194), X_test: (270000, 194), X_original: (20000, 194)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"### Preparing the Data with Categorical ","metadata":{}},{"cell_type":"code","source":"print(f\"Shapes before encoding - X: {X.shape}, X_test: {X_test.shape}, X_original: {X_original.shape}\")\n\ncat_cols = X.select_dtypes(include=[\"category\", \"object\"]).columns.tolist()\nprint(f\"Categorical columns to encode: {cat_cols}\")\n\ncat_transformer = CategoryMeanTransformer(cat_cols=cat_cols)\ncat_transformer.fit(X, y)\n\nX = cat_transformer.transform(X)\nX_test = cat_transformer.transform(X_test)\nX_original = cat_transformer.transform(X_original)\n\nX = X.astype(np.float32)\nX_test = X_test.astype(np.float32)\nX_original = X_original.astype(np.float32)\ny_float = y.values.astype(np.float32)\n\nprint(f\"Final shapes - X: {X.shape}, X_test: {X_test.shape}, X_original: {X_original.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T08:20:55.431236Z","iopub.execute_input":"2026-01-07T08:20:55.431578Z","iopub.status.idle":"2026-01-07T08:20:57.471083Z","shell.execute_reply.started":"2026-01-07T08:20:55.431545Z","shell.execute_reply":"2026-01-07T08:20:57.470335Z"}},"outputs":[{"name":"stdout","text":"Shapes before encoding - X: (630000, 194), X_test: (270000, 194), X_original: (20000, 194)\nCategorical columns to encode: ['gender', 'course', 'internet_access', 'sleep_quality', 'study_method', 'facility_rating', 'exam_difficulty']\nFinal shapes - X: (630000, 194), X_test: (270000, 194), X_original: (20000, 194)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"### Training ","metadata":{}},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*50)\nprint(\"TRAINING SINGLE XGBOOST MODEL\")\nprint(\"=\"*50)\n\nxgb_params = {\n    \"objective\": \"reg:squarederror\",\n    \"learning_rate\": 0.03,             \n    \"max_depth\": 7,                    \n    \"subsample\": 0.8,                  \n    \"colsample_bytree\": 0.85,           \n    \"colsample_bylevel\": 0.85,        \n    \"colsample_bynode\": 0.9,           \n    \"min_child_weight\": 4,            \n    \"gamma\": 0.15,                    \n    \"lambda\": 1.5,                     \n    \"alpha\": 0.08,                      \n    \"max_delta_step\": 2,               \n    \"eval_metric\": \"rmse\",            \n    \"tree_method\": \"hist\",              \n    \"grow_policy\": \"lossguide\",       \n    \"verbosity\": 0,                     \n    \"seed\": 42,  \n}\n\ny_bins = pd.qcut(y, q=10, labels=False, duplicates='drop').astype(int)\nkf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n\noof_predictions = np.zeros(len(X), dtype=np.float32)\ntest_predictions = []\nfold_metrics = []\n\nfor fold, (train_idx, val_idx) in enumerate(kf.split(X, y_bins), start=1):\n    print(f\"\\nFold {fold}/10\")\n    print(\"-\" * 30)\n    \n    X_train, X_val = X.iloc[train_idx].copy(), X.iloc[val_idx].copy()\n    y_train, y_val = y_float[train_idx], y_float[val_idx]\n    \n    dtrain = xgb.DMatrix(X_train, label=y_train)\n    dval = xgb.DMatrix(X_val, label=y_val)\n    dtest = xgb.DMatrix(X_test)\n    \n    evals = [(dtrain, \"train\"), (dval, \"valid\")]\n    \n    xgb_model = xgb.train(\n        params=xgb_params,\n        dtrain=dtrain,\n        num_boost_round=3000,\n        evals=evals,\n        early_stopping_rounds=50,\n        verbose_eval=False,\n    )\n    \n    val_preds = np.clip(xgb_model.predict(dval), 0, 100)\n    test_pred = np.clip(xgb_model.predict(dtest), 0, 100)\n    \n    oof_predictions[val_idx] = val_preds\n    test_predictions.append(test_pred)\n    \n    rmse = np.sqrt(mean_squared_error(y_val, val_preds))\n    mae = mean_absolute_error(y_val, val_preds)\n    \n    print(f\"  RMSE: {rmse:.5f} | MAE: {mae:.5f}\")\n    print(f\"  Best iteration: {xgb_model.best_iteration}\")\n    \n    fold_metrics.append({\"fold\": fold, \"rmse\": rmse, \"mae\": mae})\n\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"FINAL RESULTS\")\nprint(\"=\"*50)\n\ntest_predictions = np.mean(test_predictions, axis=0)\noof_rmse = np.sqrt(mean_squared_error(y_float, oof_predictions))\noof_mae = mean_absolute_error(y_float, oof_predictions)\n\nprint(f\"\\nOOF RMSE: {oof_rmse:.5f}\")\nprint(f\"OOF MAE: {oof_mae:.5f}\")\nprint(f\"Prediction range: [{test_predictions.min():.2f}, {test_predictions.max():.2f}]\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T08:44:13.180670Z","iopub.execute_input":"2026-01-07T08:44:13.181104Z","iopub.status.idle":"2026-01-07T10:01:13.096115Z","shell.execute_reply.started":"2026-01-07T08:44:13.181077Z","shell.execute_reply":"2026-01-07T10:01:13.095348Z"}},"outputs":[{"name":"stdout","text":"\n==================================================\nTRAINING SINGLE XGBOOST MODEL\n==================================================\n\nFold 1/10\n------------------------------\n  RMSE: 8.74065 | MAE: 6.95260\n  Best iteration: 2777\n\nFold 2/10\n------------------------------\n  RMSE: 8.70992 | MAE: 6.94128\n  Best iteration: 2796\n\nFold 3/10\n------------------------------\n  RMSE: 8.74281 | MAE: 6.97829\n  Best iteration: 2612\n\nFold 4/10\n------------------------------\n  RMSE: 8.74575 | MAE: 6.97026\n  Best iteration: 2655\n\nFold 5/10\n------------------------------\n  RMSE: 8.74174 | MAE: 6.95816\n  Best iteration: 2936\n\nFold 6/10\n------------------------------\n  RMSE: 8.74398 | MAE: 6.96240\n  Best iteration: 2462\n\nFold 7/10\n------------------------------\n  RMSE: 8.75723 | MAE: 6.97920\n  Best iteration: 2809\n\nFold 8/10\n------------------------------\n  RMSE: 8.75144 | MAE: 6.95824\n  Best iteration: 2968\n\nFold 9/10\n------------------------------\n  RMSE: 8.72633 | MAE: 6.94594\n  Best iteration: 2793\n\nFold 10/10\n------------------------------\n  RMSE: 8.70706 | MAE: 6.93726\n  Best iteration: 2904\n\n==================================================\nFINAL RESULTS\n==================================================\n\nOOF RMSE: 8.73670\nOOF MAE: 6.95836\nPrediction range: [16.31, 100.00]\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"### Submission","metadata":{}},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*50)\nprint(\"SAVING RESULTS\")\nprint(\"=\"*50)\n\noof_df = pd.DataFrame({\n    ID_COL: train_df[ID_COL],\n    TARGET: oof_predictions\n})\noof_df.to_csv(\"oof_df.csv\", index=False)\n\nsubmission_df[TARGET] = test_predictions\nsubmission_df.to_csv(\"submission.csv\", index=False)\n\nprint(\"\\nFiles saved successfully!\")\nprint(f\"  - oof_df.csv: {oof_df.shape}\")\nprint(f\"  - submission.csv: {submission_df.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T10:01:13.097485Z","iopub.execute_input":"2026-01-07T10:01:13.097725Z","iopub.status.idle":"2026-01-07T10:01:14.254091Z","shell.execute_reply.started":"2026-01-07T10:01:13.097701Z","shell.execute_reply":"2026-01-07T10:01:14.253331Z"}},"outputs":[{"name":"stdout","text":"\n==================================================\nSAVING RESULTS\n==================================================\n\nFiles saved successfully!\n  - oof_df.csv: (630000, 2)\n  - submission.csv: (270000, 2)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"submission_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T10:01:14.255094Z","iopub.execute_input":"2026-01-07T10:01:14.255393Z","iopub.status.idle":"2026-01-07T10:01:14.274009Z","shell.execute_reply.started":"2026-01-07T10:01:14.255365Z","shell.execute_reply":"2026-01-07T10:01:14.273470Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"       id  exam_score\n0  630000   69.817101\n1  630001   70.960045\n2  630002   88.604630\n3  630003   55.694519\n4  630004   47.895805","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>exam_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>630000</td>\n      <td>69.817101</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>630001</td>\n      <td>70.960045</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>630002</td>\n      <td>88.604630</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>630003</td>\n      <td>55.694519</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>630004</td>\n      <td>47.895805</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"Acknowledgement: [https://www.kaggle.com/code/mdevian/ps-s6e1-clean-strong-baseline-ridge-xgb-fe](https://www.kaggle.com/code/mdevian/ps-s6e1-clean-strong-baseline-ridge-xgb-fe)","metadata":{}}]}