{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":119082,"databundleVersionId":14993753,"sourceType":"competition"},{"sourceId":13904981,"sourceType":"datasetVersion","datasetId":8762382}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/samithsachidanandan/ps-s6e1-ridge-xgb?scriptVersionId=290405706\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"Acknowledgement: \n\n[https://www.kaggle.com/code/mdevian/ps-s6e1-clean-strong-baseline-ridge-xgb-fe](https://www.kaggle.com/code/mdevian/ps-s6e1-clean-strong-baseline-ridge-xgb-fe)\n[https://www.kaggle.com/code/act18l/s6e1-single-xgb-add-categorymean](https://www.kaggle.com/code/act18l/s6e1-single-xgb-add-categorymean)","metadata":{}},{"cell_type":"markdown","source":"### Importing Libraries and Loading the Data ","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\nimport xgboost as xgb\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import root_mean_squared_error,mean_absolute_error\nfrom sklearn.preprocessing import TargetEncoder\n\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.linear_model import RidgeCV\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nnp.random.seed(42)\n\ntrain_file = \"/kaggle/input/playground-series-s6e1/train.csv\"\ntest_file = \"/kaggle/input/playground-series-s6e1/test.csv\"\noriginal_file = \"/kaggle/input/exam-score-prediction-dataset/Exam_Score_Prediction.csv\"\n\ntrain_df = pd.read_csv(train_file)\ntest_df = pd.read_csv(test_file)\noriginal_df = pd.read_csv(original_file)\n\nsubmission_df = pd.read_csv(\"/kaggle/input/playground-series-s6e1/sample_submission.csv\")\n\nTARGET = \"exam_score\"\nID_COL = \"id\"\n\ntrain_df.shape, test_df.shape, original_df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T06:11:42.161138Z","iopub.execute_input":"2026-01-05T06:11:42.16178Z","iopub.status.idle":"2026-01-05T06:11:43.260932Z","shell.execute_reply.started":"2026-01-05T06:11:42.161752Z","shell.execute_reply":"2026-01-05T06:11:43.260401Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"((630000, 13), (270000, 12), (20000, 13))"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"### Base features","metadata":{}},{"cell_type":"code","source":"base_features = [col for col in train_df.columns if col not in [TARGET, ID_COL]]\n\n\nCATS = train_df.select_dtypes(\"object\").columns.to_list()\nprint(\"CATS:\", CATS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T05:09:52.914916Z","iopub.execute_input":"2026-01-05T05:09:52.915152Z","iopub.status.idle":"2026-01-05T05:09:52.974427Z","shell.execute_reply.started":"2026-01-05T05:09:52.915131Z","shell.execute_reply":"2026-01-05T05:09:52.973594Z"}},"outputs":[{"name":"stdout","text":"CATS: ['gender', 'course', 'internet_access', 'sleep_quality', 'study_method', 'facility_rating', 'exam_difficulty']\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### Feature Engineering","metadata":{}},{"cell_type":"code","source":"\n\nclass CategoryMeanTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self, cat_cols=None):\n        self.cat_cols = cat_cols\n        self.mappings_ = {}\n    \n    def fit(self, X, y):\n        X = X.copy()\n        if self.cat_cols is None:\n            self.cat_cols = X.select_dtypes(include=['category', 'object']).columns.tolist()\n        self.mappings_ = {}\n        for col in self.cat_cols:\n            df_temp = pd.DataFrame({col: X[col], 'y': y})\n            group_means = df_temp.groupby(col, dropna=False)['y'].mean()\n            sorted_categories = group_means.sort_values().index\n            self.mappings_[col] = {cat: i for i, cat in enumerate(sorted_categories)}\n        return self\n\n    def transform(self, X, y=None):\n        X = X.copy()\n        for col, mapping in self.mappings_.items():\n            if col in X.columns:\n                X[col] = X[col].map(mapping).astype(np.float32)\n        return X","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T05:09:52.975447Z","iopub.execute_input":"2026-01-05T05:09:52.975808Z","iopub.status.idle":"2026-01-05T05:09:52.984089Z","shell.execute_reply.started":"2026-01-05T05:09:52.975776Z","shell.execute_reply":"2026-01-05T05:09:52.983384Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def preprocess(df):\n\n    df_temp = df.copy()\n    eps = 1e-5\n    \n    sh_pos = df_temp['study_hours'].clip(lower=0)\n    ca_pos = df_temp['class_attendance'].clip(lower=0)\n    sl_pos = df_temp['sleep_hours'].clip(lower=0)\n    ag_pos = df_temp['age'].clip(lower=0)\n    \n    df_temp['study_hours_squared'] = df_temp['study_hours'] ** 2\n    df_temp['study_hours_cubed'] = df_temp['study_hours'] ** 3\n    df_temp['study_hours_quartic'] = df_temp['study_hours'] ** 4\n    df_temp['class_attendance_squared'] = df_temp['class_attendance'] ** 2\n    df_temp['class_attendance_cubed'] = df_temp['class_attendance'] ** 3\n    df_temp['sleep_hours_squared'] = df_temp['sleep_hours'] ** 2\n    df_temp['sleep_hours_cubed'] = df_temp['sleep_hours'] ** 3\n    df_temp['age_squared'] = df_temp['age'] ** 2\n    df_temp['age_cubed'] = df_temp['age'] ** 3\n    \n    df_temp['log_study_hours'] = np.log1p(sh_pos)\n    df_temp['log_class_attendance'] = np.log1p(ca_pos)\n    df_temp['log_sleep_hours'] = np.log1p(sl_pos)\n    df_temp['sqrt_study_hours'] = np.sqrt(sh_pos)\n    df_temp['sqrt_class_attendance'] = np.sqrt(ca_pos)\n    \n    df_temp['inv_sleep'] = 1.0 / (sl_pos + 1.0)\n    df_temp['inv_study'] = 1.0 / (sh_pos + 1.0)\n    df_temp['inv_attendance'] = 1.0 / (ca_pos + 1.0)\n    \n    df_temp['study_tanh'] = np.tanh(df_temp['study_hours'] / 10.0)\n    df_temp['sleep_tanh'] = np.tanh(df_temp['sleep_hours'] / 10.0)\n    df_temp['attendance_tanh'] = np.tanh(df_temp['class_attendance'] / 100.0)\n    \n    df_temp['study_sigmoid'] = 1.0 / (1.0 + np.exp(-(df_temp['study_hours'] - 5.0)))\n    df_temp['sleep_sigmoid'] = 1.0 / (1.0 + np.exp(-(df_temp['sleep_hours'] - 7.0)))\n    df_temp['attendance_sigmoid'] = 1.0 / (1.0 + np.exp(-(df_temp['class_attendance'] - 85.0) / 8.0))\n    \n    df_temp['study_hours_times_attendance'] = df_temp['study_hours'] * df_temp['class_attendance']\n    df_temp['study_hours_times_sleep'] = df_temp['study_hours'] * df_temp['sleep_hours']\n    df_temp['attendance_times_sleep'] = df_temp['class_attendance'] * df_temp['sleep_hours']\n    df_temp['age_times_study_hours'] = df_temp['age'] * df_temp['study_hours']\n    df_temp['age_times_attendance'] = df_temp['age'] * df_temp['class_attendance']\n    df_temp['age_times_sleep_hours'] = df_temp['age'] * df_temp['sleep_hours']\n    \n    df_temp['study_center_5'] = df_temp['study_hours'] - 5.0\n    df_temp['sleep_center_7'] = df_temp['sleep_hours'] - 7.0\n    df_temp['att_center_85'] = df_temp['class_attendance'] - 85.0\n    df_temp['study_center_sq'] = df_temp['study_center_5'] ** 2\n    df_temp['sleep_center_sq'] = df_temp['sleep_center_7'] ** 2\n    df_temp['att_center_sq'] = df_temp['att_center_85'] ** 2\n    \n    df_temp['study_hours_over_sleep'] = df_temp['study_hours'] / (df_temp['sleep_hours'] + eps)\n    df_temp['attendance_over_sleep'] = df_temp['class_attendance'] / (df_temp['sleep_hours'] + eps)\n    df_temp['attendance_over_study'] = df_temp['class_attendance'] / (df_temp['study_hours'] + eps)\n    df_temp['sleep_over_study'] = df_temp['sleep_hours'] / (df_temp['study_hours'] + eps)\n    df_temp['study_over_age'] = df_temp['study_hours'] / (df_temp['age'] + eps)\n    df_temp['attendance_over_age'] = df_temp['class_attendance'] / (df_temp['age'] + eps)\n    \n    df_temp['study_hours_clip'] = df_temp['study_hours'].clip(0, 12)\n    df_temp['sleep_hours_clip'] = df_temp['sleep_hours'].clip(0, 12)\n    df_temp['attendance_clip'] = df_temp['class_attendance'].clip(0, 100)\n    \n    df_temp['sleep_gap_8'] = (df_temp['sleep_hours'] - 8.0).abs()\n    df_temp['sleep_gap_7'] = (df_temp['sleep_hours'] - 7.0).abs()\n    df_temp['attendance_gap_100'] = (df_temp['class_attendance'] - 100.0).abs()\n    df_temp['attendance_gap_90'] = (df_temp['class_attendance'] - 90.0).abs()\n    df_temp['study_gap_6'] = (df_temp['study_hours'] - 6.0).abs()\n    df_temp['study_gap_8'] = (df_temp['study_hours'] - 8.0).abs()\n    \n    df_temp['age_bin_num'] = pd.cut(df_temp['age'], bins=[0, 17, 19, 21, 23, 100], labels=[0, 1, 2, 3, 4]).astype(float)\n    df_temp['study_bin_num'] = pd.cut(df_temp['study_hours'], bins=[-1, 2, 4, 6, 8, 100], labels=[0, 1, 2, 3, 4]).astype(float)\n    df_temp['sleep_bin_num'] = pd.cut(df_temp['sleep_hours'], bins=[-1, 5, 6, 7, 8, 100], labels=[0, 1, 2, 3, 4]).astype(float)\n    df_temp['attendance_bin_num'] = pd.cut(df_temp['class_attendance'], bins=[-1, 60, 75, 85, 95, 101], labels=[0, 1, 2, 3, 4]).astype(float)\n    \n\n    sleep_quality_map = {'poor': 0, 'average': 1, 'good': 2}\n    facility_rating_map = {'low': 0, 'medium': 1, 'high': 2}\n    exam_difficulty_map = {'easy': 0, 'moderate': 1, 'hard': 2}\n    gender_map = {'male': 0, 'female': 1}\n    internet_access_map = {'no': 0, 'yes': 1}\n    \n\n    df_temp['sleep_quality_numeric'] = df_temp['sleep_quality'].map(sleep_quality_map).fillna(1).astype(int)\n    df_temp['facility_rating_numeric'] = df_temp['facility_rating'].map(facility_rating_map).fillna(1).astype(int)\n    df_temp['exam_difficulty_numeric'] = df_temp['exam_difficulty'].map(exam_difficulty_map).fillna(1).astype(int)\n    df_temp['gender_numeric'] = df_temp['gender'].map(gender_map).fillna(0).astype(int) if 'gender' in df_temp.columns else 0\n    df_temp['internet_access_numeric'] = df_temp['internet_access'].map(internet_access_map).fillna(0).astype(int) if 'internet_access' in df_temp.columns else 0\n    \n  \n    if 'study_method' in df_temp.columns:\n        study_methods = df_temp['study_method'].unique()\n        study_method_map = {method: i for i, method in enumerate(sorted(study_methods))}\n        df_temp['study_method_numeric'] = df_temp['study_method'].map(study_method_map).fillna(0).astype(int)\n    else:\n        df_temp['study_method_numeric'] = 0\n    \n    if 'course' in df_temp.columns:\n        courses = df_temp['course'].unique()\n        course_map = {course: i for i, course in enumerate(sorted(courses))}\n        df_temp['course_numeric'] = df_temp['course'].map(course_map).fillna(0).astype(int)\n    else:\n        df_temp['course_numeric'] = 0\n    \n\n    df_temp['study_hours_times_sleep_quality'] = df_temp['study_hours'] * df_temp['sleep_quality_numeric']\n    df_temp['attendance_times_facility'] = df_temp['class_attendance'] * df_temp['facility_rating_numeric']\n    df_temp['sleep_hours_times_difficulty'] = df_temp['sleep_hours'] * df_temp['exam_difficulty_numeric']\n    \n    df_temp['facility_x_sleepq'] = df_temp['facility_rating_numeric'] * df_temp['sleep_quality_numeric']\n    df_temp['difficulty_x_facility'] = df_temp['exam_difficulty_numeric'] * df_temp['facility_rating_numeric']\n    df_temp['difficulty_x_sleepq'] = df_temp['exam_difficulty_numeric'] * df_temp['sleep_quality_numeric']\n    \n    df_temp['high_att_low_sleep'] = ((df_temp['class_attendance'] >= 90) & (df_temp['sleep_hours'] <= 6)).astype(int)\n    df_temp['high_att_high_study'] = ((df_temp['class_attendance'] >= 90) & (df_temp['study_hours'] >= 6)).astype(int)\n    df_temp['low_att_high_study'] = ((df_temp['class_attendance'] <= 60) & (df_temp['study_hours'] >= 7)).astype(int)\n    df_temp['ideal_sleep_flag'] = ((df_temp['sleep_hours'] >= 7) & (df_temp['sleep_hours'] <= 9)).astype(int)\n    df_temp['short_sleep_flag'] = (df_temp['sleep_hours'] <= 5.5).astype(int)\n    df_temp['high_study_flag'] = (df_temp['study_hours'] >= 7).astype(int)\n    \n    df_temp['efficiency'] = (df_temp['study_hours'] * df_temp['class_attendance']) / (df_temp['sleep_hours'] + 1)\n    df_temp['efficiency2'] = (df_temp['study_hours_clip'] * df_temp['attendance_clip']) / (df_temp['sleep_hours_clip'] + 1)\n    df_temp['weighted_sum'] = (0.06 * df_temp['class_attendance'] + 2.0 * df_temp['study_hours'] + 1.2 * df_temp['sleep_hours'])\n    df_temp['weighted_sum_x_difficulty'] = df_temp['weighted_sum'] * (1.0 + 0.2 * df_temp['exam_difficulty_numeric'])\n\n    df_temp['study_rank'] = sh_pos.rank(pct=True)\n    df_temp['attendance_rank'] = ca_pos.rank(pct=True)\n    df_temp['sleep_rank'] = sl_pos.rank(pct=True)\n    df_temp['age_rank'] = ag_pos.rank(pct=True)\n\n    df_temp['study_z'] = (sh_pos - sh_pos.mean()) / (sh_pos.std() + eps)\n    df_temp['attendance_z'] = (ca_pos - ca_pos.mean()) / (ca_pos.std() + eps)\n    df_temp['sleep_z'] = (sl_pos - sl_pos.mean()) / (sl_pos.std() + eps)\n\n    df_temp['harmonic_effort'] = 3 / (\n        (1 / (sh_pos + eps)) +\n        (1 / (ca_pos + eps)) +\n        (1 / (sl_pos + eps))\n    )\n\n    df_temp['geo_effort'] = (\n        (sh_pos + 1) *\n        (ca_pos + 1) *\n        (sl_pos + 1)\n    ) ** (1 / 3)\n\n    df_temp['study_above_6'] = np.maximum(0, sh_pos - 6)\n    df_temp['study_above_8'] = np.maximum(0, sh_pos - 8)\n    df_temp['sleep_below_6'] = np.maximum(0, 6 - sl_pos)\n    df_temp['attendance_below_75'] = np.maximum(0, 75 - ca_pos)\n\n    df_temp['log_study_sleep_ratio'] = np.log1p(sh_pos) - np.log1p(sl_pos)\n    df_temp['log_att_study_ratio'] = np.log1p(ca_pos) - np.log1p(sh_pos)\n    \n\n    df_temp['study_method_x_study_hours'] = df_temp['study_hours'] * df_temp['study_method_numeric']\n    df_temp['course_difficulty'] = df_temp['course_numeric'] * df_temp['exam_difficulty_numeric']\n    df_temp['internet_x_efficiency'] = (df_temp['study_hours'] * df_temp['class_attendance'] / \n                                        (df_temp['sleep_hours'] + 1)) * df_temp['internet_access_numeric']\n    \n\n    df_temp['sqrt_study_hours_x_attendance'] = df_temp['sqrt_study_hours'] * df_temp['class_attendance']\n    df_temp['efficiency_cubed'] = ((df_temp['study_hours'] * df_temp['class_attendance'] / \n                                    (df_temp['sleep_hours'] + 1)) ** 1.5).fillna(0)\n    \n\n    df_temp['sleep_quality_x_study_z'] = df_temp['sleep_quality_numeric'] * df_temp['study_z']\n    df_temp['facility_x_attendance'] = df_temp['facility_rating_numeric'] * df_temp['class_attendance']\n    \n\n    df_temp['study_hours_x_sleep_quality'] = df_temp['study_hours'] * df_temp['sleep_quality_numeric']\n    df_temp['attendance_x_internet'] = df_temp['class_attendance'] * df_temp['internet_access_numeric']\n    df_temp['course_x_attendance'] = df_temp['course_numeric'] * df_temp['class_attendance']\n    df_temp['study_method_x_efficiency'] = df_temp['study_method_numeric'] * df_temp['efficiency']\n    \n\n    \n    numeric_features = [\n        'study_hours_squared', 'study_hours_cubed', 'study_hours_quartic',\n        'class_attendance_squared', 'class_attendance_cubed',\n        'sleep_hours_squared', 'sleep_hours_cubed',\n        'age_squared', 'age_cubed',\n        'log_study_hours', 'log_class_attendance', 'log_sleep_hours',\n        'sqrt_study_hours', 'sqrt_class_attendance',\n        'inv_sleep', 'inv_study', 'inv_attendance',\n        'study_tanh', 'sleep_tanh', 'attendance_tanh',\n        'study_sigmoid', 'sleep_sigmoid', 'attendance_sigmoid',\n        'study_hours_times_attendance', 'study_hours_times_sleep', 'attendance_times_sleep',\n        'age_times_study_hours', 'age_times_attendance', 'age_times_sleep_hours',\n        'study_center_5', 'sleep_center_7', 'att_center_85',\n        'study_center_sq', 'sleep_center_sq', 'att_center_sq',\n        'study_hours_over_sleep', 'attendance_over_sleep',\n        'attendance_over_study', 'sleep_over_study',\n        'study_over_age', 'attendance_over_age',\n        'study_hours_clip', 'sleep_hours_clip', 'attendance_clip',\n        'sleep_gap_8', 'sleep_gap_7',\n        'attendance_gap_100', 'attendance_gap_90',\n        'study_gap_6', 'study_gap_8',\n        'age_bin_num', 'study_bin_num', 'sleep_bin_num', 'attendance_bin_num',\n        'sleep_quality_numeric', 'facility_rating_numeric', 'exam_difficulty_numeric',\n        'study_hours_times_sleep_quality', 'attendance_times_facility', 'sleep_hours_times_difficulty',\n        'facility_x_sleepq', 'difficulty_x_facility', 'difficulty_x_sleepq',\n        'high_att_low_sleep', 'high_att_high_study', 'low_att_high_study',\n        'ideal_sleep_flag', 'short_sleep_flag', 'high_study_flag',\n        'efficiency', 'efficiency2',\n        'weighted_sum', 'weighted_sum_x_difficulty',\n        'study_rank', 'attendance_rank', 'sleep_rank', 'age_rank',\n        'study_z', 'attendance_z', 'sleep_z',\n        'harmonic_effort', 'geo_effort',\n        'study_above_6', 'study_above_8',\n        'sleep_below_6', 'attendance_below_75',\n        'log_study_sleep_ratio', 'log_att_study_ratio',\n        'study_method_x_study_hours', 'course_difficulty', 'internet_x_efficiency',\n        'sqrt_study_hours_x_attendance', 'efficiency_cubed',\n        'sleep_quality_x_study_z', 'facility_x_attendance',\n        'study_hours_x_sleep_quality', 'attendance_x_internet',\n        'course_x_attendance', 'study_method_x_efficiency',\n    ]\n    \n    return df_temp[base_features + numeric_features], numeric_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T05:09:52.985041Z","iopub.execute_input":"2026-01-05T05:09:52.985321Z","iopub.status.idle":"2026-01-05T05:09:53.015713Z","shell.execute_reply.started":"2026-01-05T05:09:52.985295Z","shell.execute_reply":"2026-01-05T05:09:53.014971Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### Preprocessing and Preparing the Data","metadata":{}},{"cell_type":"code","source":"X_raw, numeric_cols = preprocess(train_df)\ny = train_df[TARGET].reset_index(drop=True)\n\nX_test_raw, _ = preprocess(test_df)\nX_orig_raw, _ = preprocess(original_df)\ny_orig = original_df[TARGET].reset_index(drop=True)\n\n\ny = y.clip(0, 100)\ny_orig = y_orig.clip(0, 100)\n\nfull_data = pd.concat([X_raw, X_test_raw, X_orig_raw], axis=0, ignore_index=True)\n\n\nfor col in numeric_cols:\n    full_data[col] = full_data[col].astype(float)\n\n\nX = full_data.iloc[:len(train_df)].copy()\nX_test = full_data.iloc[len(train_df):len(train_df) + len(test_df)].copy()\nX_original = full_data.iloc[len(train_df) + len(test_df):].copy()\n\nprint(f\"Feature shapes - X: {X.shape}, X_test: {X_test.shape}, X_original: {X_original.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T05:09:53.017194Z","iopub.execute_input":"2026-01-05T05:09:53.017492Z","iopub.status.idle":"2026-01-05T05:09:56.754897Z","shell.execute_reply.started":"2026-01-05T05:09:53.017461Z","shell.execute_reply":"2026-01-05T05:09:56.754275Z"}},"outputs":[{"name":"stdout","text":"Feature shapes - X: (630000, 110), X_test: (270000, 110), X_original: (20000, 110)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"### Preparing the Data with Categorical ","metadata":{}},{"cell_type":"code","source":"print(f\"Shapes before encoding - X: {X.shape}, X_test: {X_test.shape}, X_original: {X_original.shape}\")\n\ncat_cols = X.select_dtypes(include=[\"category\", \"object\"]).columns.tolist()\nprint(f\"Categorical columns to encode: {cat_cols}\")\n\ncat_transformer = CategoryMeanTransformer(cat_cols=cat_cols)\ncat_transformer.fit(X, y)\n\nX = cat_transformer.transform(X)\nX_test = cat_transformer.transform(X_test)\nX_original = cat_transformer.transform(X_original)\n\nX = X.astype(np.float32)\nX_test = X_test.astype(np.float32)\nX_original = X_original.astype(np.float32)\ny_float = y.values.astype(np.float32)\n\nprint(f\"Final shapes - X: {X.shape}, X_test: {X_test.shape}, X_original: {X_original.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T05:09:56.755751Z","iopub.execute_input":"2026-01-05T05:09:56.75601Z","iopub.status.idle":"2026-01-05T05:09:58.255028Z","shell.execute_reply.started":"2026-01-05T05:09:56.755989Z","shell.execute_reply":"2026-01-05T05:09:58.254259Z"}},"outputs":[{"name":"stdout","text":"Shapes before encoding - X: (630000, 110), X_test: (270000, 110), X_original: (20000, 110)\nCategorical columns to encode: ['gender', 'course', 'internet_access', 'sleep_quality', 'study_method', 'facility_rating', 'exam_difficulty']\nFinal shapes - X: (630000, 110), X_test: (270000, 110), X_original: (20000, 110)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"### Training ","metadata":{}},{"cell_type":"code","source":"print(\"\\nTraining Ridge Regression on full training data...\")\n\n\nscaler_ridge = StandardScaler()\nX_ridge_scaled = scaler_ridge.fit_transform(X)\nX_test_ridge_scaled = scaler_ridge.transform(X_test)\n\n\n\n\nalphas = np.logspace(-2, 5, 100)\nridge_cv = RidgeCV(alphas=alphas, cv=5, scoring='neg_mean_squared_error')\nridge_cv.fit(X_ridge_scaled, y_float)\n\n\n\n\nridge_oof = ridge_cv.predict(X_ridge_scaled)\nridge_test = ridge_cv.predict(X_test_ridge_scaled)\n\n\nridge_oof = np.clip(ridge_oof, 0, 100)\nridge_test = np.clip(ridge_test, 0, 100)\n\nridge_rmse = np.sqrt(mean_squared_error(y_float, ridge_oof))\nridge_mae = mean_absolute_error(y_float, ridge_oof)\n\nprint(f\"\\nRidge Regression Results:\")\nprint(f\"  OOF RMSE: {ridge_rmse:.5f}\")\nprint(f\"  OOF MAE:  {ridge_mae:.5f}\")\n\n\nresiduals = y_float - ridge_oof\n\nprint(\"\\nTraining XGBoost to predict residuals using 10-fold CV...\\n\")\n\n\nresidual_bins = pd.qcut(residuals, q=10, labels=False, duplicates='drop').astype(int)\n\ndtest_residual = xgb.DMatrix(X_test)\n\n\nxgb_residual_params = {\n    \"objective\": \"reg:squarederror\",\n    \"learning_rate\": 0.05,\n    \"max_depth\": 8,\n    \"subsample\": 0.85,\n    \"colsample_bytree\": 0.75,\n    \"colsample_bynode\": 0.8,\n    \"min_child_weight\": 2,\n    \"gamma\": 0.05,\n    \"lambda\": 0.8,\n    \"alpha\": 0.02,\n    \"eval_metric\": \"rmse\",\n    \"tree_method\": \"hist\",\n    \"verbosity\": 0,\n    \"seed\": 42,\n}\n\noof_residual_pred = np.zeros(len(X), dtype=np.float32)\ntest_residual_preds = []\nresidual_fold_metrics = []\n\nkf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n\nfor fold, (train_idx, val_idx) in enumerate(kf.split(X, residual_bins), start=1):\n    print(f\"Fold {fold}/10 - Training XGBoost on residuals...\")\n    \n    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n    residual_train = residuals[train_idx]\n    residual_val = residuals[val_idx]\n    \n    dtrain = xgb.DMatrix(X_train, label=residual_train)\n    dval = xgb.DMatrix(X_val, label=residual_val)\n    evals = [(dtrain, \"train\"), (dval, \"valid\")]\n    \n    xgb_residual_model = xgb.train(\n        params=xgb_residual_params,\n        dtrain=dtrain,\n        num_boost_round=3000,\n        evals=evals,\n        early_stopping_rounds=50,\n        verbose_eval=False,\n    )\n    \n\n    residual_val_pred = xgb_residual_model.predict(dval)\n    oof_residual_pred[val_idx] = residual_val_pred\n    \n    residual_test_pred = xgb_residual_model.predict(dtest_residual)\n    test_residual_preds.append(residual_test_pred)\n    \n    residual_rmse = np.sqrt(mean_squared_error(residual_val, residual_val_pred))\n    residual_mae = mean_absolute_error(residual_val, residual_val_pred)\n    \n    print(f\"  RMSE (residuals): {residual_rmse:.5f} | MAE: {residual_mae:.5f}\")\n    print(f\"  Best iteration: {xgb_residual_model.best_iteration}\")\n    \n    residual_fold_metrics.append({\n        \"fold\": fold,\n        \"rmse\": residual_rmse,\n        \"mae\": residual_mae,\n    })\n\n\ntest_residual_preds = np.mean(test_residual_preds, axis=0)\n\n\nxgb_residual_rmse = np.sqrt(mean_squared_error(residuals, oof_residual_pred))\nxgb_residual_mae = mean_absolute_error(residuals, oof_residual_pred)\n\nprint(f\"\\n{'='*70}\")\nprint(\"RESIDUAL MODEL PERFORMANCE\")\nprint(f\"{'='*70}\")\nprint(f\"XGBoost Residual OOF RMSE: {xgb_residual_rmse:.5f}\")\nprint(f\"XGBoost Residual OOF MAE:  {xgb_residual_mae:.5f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T06:13:36.015537Z","iopub.execute_input":"2026-01-05T06:13:36.016056Z","iopub.status.idle":"2026-01-05T06:49:07.87741Z","shell.execute_reply.started":"2026-01-05T06:13:36.016029Z","shell.execute_reply":"2026-01-05T06:49:07.876754Z"}},"outputs":[{"name":"stdout","text":"\nTraining Ridge Regression on full training data...\n\nRidge Regression Results:\n  OOF RMSE: 8.93853\n  OOF MAE:  7.14107\n\nTraining XGBoost to predict residuals using 10-fold CV...\n\nFold 1/10 - Training XGBoost on residuals...\n  RMSE (residuals): 8.70950 | MAE: 6.94075\n  Best iteration: 657\nFold 2/10 - Training XGBoost on residuals...\n  RMSE (residuals): 8.71449 | MAE: 6.94469\n  Best iteration: 583\nFold 3/10 - Training XGBoost on residuals...\n  RMSE (residuals): 8.70459 | MAE: 6.93785\n  Best iteration: 578\nFold 4/10 - Training XGBoost on residuals...\n  RMSE (residuals): 8.70577 | MAE: 6.93693\n  Best iteration: 650\nFold 5/10 - Training XGBoost on residuals...\n  RMSE (residuals): 8.70871 | MAE: 6.93639\n  Best iteration: 846\nFold 6/10 - Training XGBoost on residuals...\n  RMSE (residuals): 8.74528 | MAE: 6.96089\n  Best iteration: 748\nFold 7/10 - Training XGBoost on residuals...\n  RMSE (residuals): 8.72031 | MAE: 6.93952\n  Best iteration: 721\nFold 8/10 - Training XGBoost on residuals...\n  RMSE (residuals): 8.71963 | MAE: 6.94016\n  Best iteration: 685\nFold 9/10 - Training XGBoost on residuals...\n  RMSE (residuals): 8.69683 | MAE: 6.93553\n  Best iteration: 741\nFold 10/10 - Training XGBoost on residuals...\n  RMSE (residuals): 8.77463 | MAE: 6.98312\n  Best iteration: 740\n\n======================================================================\nRESIDUAL MODEL PERFORMANCE\n======================================================================\nXGBoost Residual OOF RMSE: 8.72000\nXGBoost Residual OOF MAE:  6.94558\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*70)\nprint(\"STEP 4: STACKING - COMBINE RIDGE + RESIDUAL PREDICTIONS\")\nprint(\"=\"*70)\n\n\n\nbest_stacking_rmse = float('inf')\nbest_correction_weight = None\n\n\ncorrection_weights = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n\nfor corr_w in correction_weights:\n\n    stacking_oof = ridge_oof + corr_w * oof_residual_pred\n    stacking_oof = np.clip(stacking_oof, 0, 100)\n    \n    stacking_rmse = np.sqrt(mean_squared_error(y_float, stacking_oof))\n    \n    print(f\"Correction weight: {corr_w:.1f} → Stacking RMSE: {stacking_rmse:.5f}\")\n    \n    if stacking_rmse < best_stacking_rmse:\n        best_stacking_rmse = stacking_rmse\n        best_correction_weight = corr_w\n\nprint(f\"\\n Best correction weight: {best_correction_weight:.2f}\")\nprint(f\"   Stacking RMSE: {best_stacking_rmse:.5f}\\n\")\n\n\nprint(\"=\"*70)\nprint(\"FINAL PREDICTIONS\")\nprint(\"=\"*70)\n\n\nfinal_oof = ridge_oof + best_correction_weight * oof_residual_pred\nfinal_oof = np.clip(final_oof, 0, 100)\n\n\nfinal_test = ridge_test + best_correction_weight * test_residual_preds\nfinal_test = np.clip(final_test, 0, 100)\n\nfinal_stacking_rmse = np.sqrt(mean_squared_error(y_float, final_oof))\nfinal_stacking_mae = mean_absolute_error(y_float, final_oof)\n\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"PERFORMANCE SUMMARY\")\nprint(\"=\"*70)\n\nprint(f\"\\n1. Base Model (Ridge):\")\nprint(f\"   OOF RMSE: {ridge_rmse:.5f}\")\nprint(f\"   OOF MAE:  {ridge_mae:.5f}\")\n\nprint(f\"\\n2. Meta Model (XGBoost on Residuals):\")\nprint(f\"   Residual RMSE: {xgb_residual_rmse:.5f}\")\nprint(f\"   Residual MAE:  {xgb_residual_mae:.5f}\")\n\nprint(f\"\\n3. Stacking Ensemble (Ridge + {best_correction_weight:.2f}×XGB Residual):\")\nprint(f\"   OOF RMSE: {final_stacking_rmse:.5f}\")\nprint(f\"   OOF MAE:  {final_stacking_mae:.5f}\")\n\nprint(f\"\\n4. Improvements:\")\nprint(f\"   vs Ridge:     {ridge_rmse - final_stacking_rmse:.5f} RMSE improvement\")\nprint(f\"   vs XGB+LGB ensemble (if available): {8.72268 - final_stacking_rmse:.5f} improvement\")\n\nprint(f\"\\n5. Prediction Ranges:\")\nprint(f\"   Ridge:    [{ridge_oof.min():.2f}, {ridge_oof.max():.2f}]\")\nprint(f\"   Stacking: [{final_oof.min():.2f}, {final_oof.max():.2f}]\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T06:49:07.879087Z","iopub.execute_input":"2026-01-05T06:49:07.879302Z","iopub.status.idle":"2026-01-05T06:49:07.924688Z","shell.execute_reply.started":"2026-01-05T06:49:07.879283Z","shell.execute_reply":"2026-01-05T06:49:07.923976Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nSTEP 4: STACKING - COMBINE RIDGE + RESIDUAL PREDICTIONS\n======================================================================\nCorrection weight: 0.0 → Stacking RMSE: 8.93853\nCorrection weight: 0.1 → Stacking RMSE: 8.89862\nCorrection weight: 0.2 → Stacking RMSE: 8.86261\nCorrection weight: 0.3 → Stacking RMSE: 8.83056\nCorrection weight: 0.4 → Stacking RMSE: 8.80251\nCorrection weight: 0.5 → Stacking RMSE: 8.77850\nCorrection weight: 0.6 → Stacking RMSE: 8.75855\nCorrection weight: 0.7 → Stacking RMSE: 8.74271\nCorrection weight: 0.8 → Stacking RMSE: 8.73098\nCorrection weight: 0.9 → Stacking RMSE: 8.72338\nCorrection weight: 1.0 → Stacking RMSE: 8.71993\n\n Best correction weight: 1.00\n   Stacking RMSE: 8.71993\n\n======================================================================\nFINAL PREDICTIONS\n======================================================================\n\n======================================================================\nPERFORMANCE SUMMARY\n======================================================================\n\n1. Base Model (Ridge):\n   OOF RMSE: 8.93853\n   OOF MAE:  7.14107\n\n2. Meta Model (XGBoost on Residuals):\n   Residual RMSE: 8.72000\n   Residual MAE:  6.94558\n\n3. Stacking Ensemble (Ridge + 1.00×XGB Residual):\n   OOF RMSE: 8.71993\n   OOF MAE:  6.94524\n\n4. Improvements:\n   vs Ridge:     0.21861 RMSE improvement\n   vs XGB+LGB ensemble (if available): 0.00275 improvement\n\n5. Prediction Ranges:\n   Ridge:    [13.87, 100.00]\n   Stacking: [14.07, 100.00]\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"### Submission","metadata":{}},{"cell_type":"code","source":"print(\"\\n\" + \"=\" * 50)\nprint(\"SAVING RESULTS\")\nprint(\"=\" * 50)\n\noof_df = pd.DataFrame({\n    \"id\": train_df[ID_COL], \n    TARGET: final_oof  \n})\n\noof_df.to_csv(\"oof_ridge_xgb_stacking.csv\", index=False)\n\nsubmission_df[TARGET] = final_test\nsubmission_df.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T06:49:07.925755Z","iopub.execute_input":"2026-01-05T06:49:07.926115Z","iopub.status.idle":"2026-01-05T06:49:09.055868Z","shell.execute_reply.started":"2026-01-05T06:49:07.926087Z","shell.execute_reply":"2026-01-05T06:49:09.055016Z"}},"outputs":[{"name":"stdout","text":"\n==================================================\nSAVING RESULTS\n==================================================\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"submission_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T06:49:09.057238Z","iopub.execute_input":"2026-01-05T06:49:09.05748Z","iopub.status.idle":"2026-01-05T06:49:09.0647Z","shell.execute_reply.started":"2026-01-05T06:49:09.05746Z","shell.execute_reply":"2026-01-05T06:49:09.06405Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"       id  exam_score\n0  630000   71.309814\n1  630001   70.848984\n2  630002   87.977707\n3  630003   55.544342\n4  630004   47.045559","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>exam_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>630000</td>\n      <td>71.309814</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>630001</td>\n      <td>70.848984</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>630002</td>\n      <td>87.977707</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>630003</td>\n      <td>55.544342</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>630004</td>\n      <td>47.045559</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"Acknowledgement: [https://www.kaggle.com/code/mdevian/ps-s6e1-clean-strong-baseline-ridge-xgb-fe](https://www.kaggle.com/code/mdevian/ps-s6e1-clean-strong-baseline-ridge-xgb-fe)","metadata":{}}]}