{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":102335,"databundleVersionId":12518947,"sourceType":"competition"},{"sourceId":242954653,"sourceType":"kernelVersion"}],"dockerImageVersionId":31041,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/samithsachidanandan/lb-0-72-cmi-2025-tensor-flow?scriptVersionId=244536652\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"## CMI - Detect Behavior with Sensor Data","metadata":{}},{"cell_type":"markdown","source":"The goal of this competition is to develop a predictive model that distinguishes BFRB-like and non-BFRB-like activity using data from a variety of sensors collected via a wrist-worn device. Successfully disentangling these behaviours will improve the design and accuracy of wearable BFRB-detection devices, which are relevant to a wide range of mental illnesses, ultimately strengthening the tools available to support their treatment.","metadata":{}},{"cell_type":"markdown","source":"## Importing the necessary Libraries","metadata":{}},{"cell_type":"code","source":"# Two‑Branch Human‑Activity‑Recognition Pipeline (IMU + Thermopile/TOF  + SE‑CNN + BiLSTM + Attention)\nimport os, json, joblib, numpy as np, pandas as pd\nfrom pathlib import Path\nimport warnings \nwarnings.filterwarnings(\"ignore\")\n\n\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.utils.class_weight import compute_class_weight\n\nfrom tensorflow.keras.utils import Sequence, to_categorical, pad_sequences\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import (\n    Input, Conv1D, BatchNormalization, Activation, add, MaxPooling1D, Dropout,\n    Bidirectional, LSTM, GlobalAveragePooling1D, Dense, Multiply, Reshape,\n    Lambda, Concatenate\n)\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras import backend as K\nimport tensorflow as tf\nimport polars as pl\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T13:35:33.493135Z","iopub.execute_input":"2025-06-09T13:35:33.493447Z","iopub.status.idle":"2025-06-09T13:35:33.499139Z","shell.execute_reply.started":"2025-06-09T13:35:33.49342Z","shell.execute_reply":"2025-06-09T13:35:33.498383Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"### Configuration","metadata":{}},{"cell_type":"markdown","source":"This sets the hyperparameters and paths. Can play around the these values to get higher LB score. \n\nTraining hyperparameters:\n\nBATCH_SIZE: Minibatch size.\n\nPAD_PERCENTILE: Used for sequence padding.\n\nLR_INIT: Learning rate.\n\nWD: Weight decay (L2).\n\nMIXUP_ALPHA: If using mixup augmentation.\n\nEPOCHS: Max training epochs.\n\nPATIENCE: Early stopping patience.","metadata":{}},{"cell_type":"code","source":"# (Competition metric will only be imported when TRAINing)\nTRAIN = True                     # ← set to True when you want to train\nRAW_DIR = Path(\"/kaggle/input/cmi-detect-behavior-with-sensor-data\")\nPRETRAINED_DIR = Path(\"/kaggle/input/pretrained-model\")  # used when TRAIN=False\nEXPORT_DIR = Path(\"./\")                                    # artefacts will be saved here\nBATCH_SIZE = 64\nPAD_PERCENTILE = 95\nLR_INIT = 1e-3\nWD = 3e-4\nMIXUP_ALPHA = 0.4\nEPOCHS = 160\nPATIENCE = 40\n\n\nprint(\"▶ imports ready · tensorflow\", tf.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T13:35:33.50056Z","iopub.execute_input":"2025-06-09T13:35:33.500899Z","iopub.status.idle":"2025-06-09T13:35:33.516363Z","shell.execute_reply.started":"2025-06-09T13:35:33.500882Z","shell.execute_reply":"2025-06-09T13:35:33.515766Z"}},"outputs":[{"name":"stdout","text":"▶ imports ready · tensorflow 2.18.0\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## Utility Functions","metadata":{}},{"cell_type":"markdown","source":"Utility Fucntions are having modular helper fucntions which simplify the architecture design in TensorFlow/Keras models.","metadata":{}},{"cell_type":"code","source":"#Tensor Manipulations\ndef time_sum(x):\n    return K.sum(x, axis=1)\n\ndef squeeze_last_axis(x):\n    return tf.squeeze(x, axis=-1)\n\ndef expand_last_axis(x):\n    return tf.expand_dims(x, axis=-1)\n\ndef se_block(x, reduction=8):\n    ch = x.shape[-1]\n    se = GlobalAveragePooling1D()(x)\n    se = Dense(ch // reduction, activation='relu')(se)\n    se = Dense(ch, activation='sigmoid')(se)\n    se = Reshape((1, ch))(se)\n    return Multiply()([x, se])\n\n\n# Residual CNN Block with SE\ndef residual_se_cnn_block(x, filters, kernel_size, pool_size=2, drop=0.3, wd=1e-4):\n    shortcut = x\n    for _ in range(2):\n        x = Conv1D(filters, kernel_size, padding='same', use_bias=False,\n                   kernel_regularizer=l2(wd))(x)\n        x = BatchNormalization()(x)\n        x = Activation('relu')(x)\n    x = se_block(x)\n    if shortcut.shape[-1] != filters:\n        shortcut = Conv1D(filters, 1, padding='same', use_bias=False,\n                          kernel_regularizer=l2(wd))(shortcut)\n        shortcut = BatchNormalization()(shortcut)\n    x = add([x, shortcut])\n    x = Activation('relu')(x)\n    x = MaxPooling1D(pool_size)(x)\n    x = Dropout(drop)(x)\n    return x\n\ndef attention_layer(inputs):\n    score = Dense(1, activation='tanh')(inputs)\n    score = Lambda(squeeze_last_axis)(score)\n    weights = Activation('softmax')(score)\n    weights = Lambda(expand_last_axis)(weights)\n    context = Multiply()([inputs, weights])\n    context = Lambda(time_sum)(context)\n    return context\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T13:35:33.517503Z","iopub.execute_input":"2025-06-09T13:35:33.517698Z","iopub.status.idle":"2025-06-09T13:35:33.531675Z","shell.execute_reply.started":"2025-06-09T13:35:33.517683Z","shell.execute_reply":"2025-06-09T13:35:33.531041Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## Data Helpers","metadata":{}},{"cell_type":"code","source":"# Normalizes and cleans the time series sequence. \n\ndef preprocess_sequence(df_seq: pd.DataFrame, feature_cols: list[str], scaler: StandardScaler):\n    mat = df_seq[feature_cols].ffill().bfill().fillna(0).values\n    return scaler.transform(mat).astype('float32')\n\n# MixUp the data argumentation in order to regularize the neural network. \n\nclass MixupGenerator(Sequence):\n    def __init__(self, X, y, batch_size, alpha=0.2):\n        self.X, self.y = X, y\n        self.batch = batch_size\n        self.alpha = alpha\n        self.indices = np.arange(len(X))\n    def __len__(self):\n        return int(np.ceil(len(self.X) / self.batch))\n    def __getitem__(self, i):\n        idx = self.indices[i*self.batch:(i+1)*self.batch]\n        Xb, yb = self.X[idx], self.y[idx]\n        lam = np.random.beta(self.alpha, self.alpha)\n        perm = np.random.permutation(len(Xb))\n        X_mix = lam * Xb + (1-lam) * Xb[perm]\n        y_mix = lam * yb + (1-lam) * yb[perm]\n        return X_mix, y_mix\n    def on_epoch_end(self):\n        np.random.shuffle(self.indices)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T13:35:33.532309Z","iopub.execute_input":"2025-06-09T13:35:33.532513Z","iopub.status.idle":"2025-06-09T13:35:33.547429Z","shell.execute_reply.started":"2025-06-09T13:35:33.532498Z","shell.execute_reply":"2025-06-09T13:35:33.546687Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## Model Definition - Two Branch Architecture","metadata":{}},{"cell_type":"code","source":"\n\ndef build_two_branch_model(pad_len, imu_dim, tof_dim, n_classes, wd=1e-4):\n    inp = Input(shape=(pad_len, imu_dim+tof_dim))\n    imu = Lambda(lambda t: t[:, :, :imu_dim])(inp)\n    tof = Lambda(lambda t: t[:, :, imu_dim:])(inp)\n\n    # IMU deep branch\n    x1 = residual_se_cnn_block(imu, 64, 3, drop=0.3, wd=wd)\n    x1 = residual_se_cnn_block(x1, 128, 5, drop=0.3, wd=wd)\n\n    # TOF/Thermal lighter branch\n    x2 = Conv1D(64, 3, padding='same', use_bias=False, kernel_regularizer=l2(wd))(tof)\n    x2 = BatchNormalization()(x2); x2 = Activation('relu')(x2)\n    x2 = MaxPooling1D(2)(x2); x2 = Dropout(0.3)(x2)\n    x2 = Conv1D(128, 3, padding='same', use_bias=False, kernel_regularizer=l2(wd))(x2)\n    x2 = BatchNormalization()(x2); x2 = Activation('relu')(x2)\n    x2 = MaxPooling1D(2)(x2); x2 = Dropout(0.3)(x2)\n\n    merged = Concatenate()([x1, x2])\n\n    x = Bidirectional(LSTM(128, return_sequences=True, kernel_regularizer=l2(wd)))(merged)\n    x = Dropout(0.4)(x)\n    x = attention_layer(x)\n\n    for units, drop in [(256, 0.5), (128, 0.3)]:\n        x = Dense(units, use_bias=False, kernel_regularizer=l2(wd))(x)\n        x = BatchNormalization()(x); x = Activation('relu')(x)\n        x = Dropout(drop)(x)\n\n    out = Dense(n_classes, activation='softmax', kernel_regularizer=l2(wd))(x)\n    return Model(inp, out)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T13:35:33.548749Z","iopub.execute_input":"2025-06-09T13:35:33.548999Z","iopub.status.idle":"2025-06-09T13:35:33.562728Z","shell.execute_reply.started":"2025-06-09T13:35:33.548978Z","shell.execute_reply":"2025-06-09T13:35:33.562154Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## Training / Inference Pipeline","metadata":{}},{"cell_type":"code","source":"if TRAIN:\n    print(\"▶ TRAIN MODE – loading dataset …\")\n    df = pd.read_csv(RAW_DIR / \"train.csv\")\n\n    # label encoding\n    le = LabelEncoder(); df['gesture_int'] = le.fit_transform(df['gesture'])\n    np.save(EXPORT_DIR / \"gesture_classes.npy\", le.classes_)\n\n    # feature list\n    meta_cols = {'gesture', 'gesture_int', 'sequence_type', 'behavior', 'orientation',\n                 'row_id', 'subject', 'phase', 'sequence_id', 'sequence_counter'}\n    feature_cols = [c for c in df.columns if c not in meta_cols]\n\n    imu_cols  = [c for c in feature_cols if not (c.startswith('thm_') or c.startswith('tof_'))]\n    tof_cols  = [c for c in feature_cols if c.startswith('thm_') or c.startswith('tof_')]\n    print(f\"  IMU {len(imu_cols)} | TOF/THM {len(tof_cols)} | total {len(feature_cols)} features\")\n\n    # global scaler\n    scaler = StandardScaler().fit(df[feature_cols].ffill().bfill().fillna(0).values)\n    joblib.dump(scaler, EXPORT_DIR / \"scaler.pkl\")\n\n    # build sequences\n    seq_gp = df.groupby('sequence_id')\n    X_list, y_list, lens = [], [], []\n    for seq_id, seq in seq_gp:\n        mat = preprocess_sequence(seq, feature_cols, scaler)\n        X_list.append(mat)\n        y_list.append(seq['gesture_int'].iloc[0])\n        lens.append(len(mat))\n    pad_len = int(np.percentile(lens, PAD_PERCENTILE))\n    np.save(EXPORT_DIR / \"sequence_maxlen.npy\", pad_len)\n    np.save(EXPORT_DIR / \"feature_cols.npy\", np.array(feature_cols))\n\n    # Get gesture labels and groups\n    y_labels = np.array(y_list)\n    groups = np.array([seq_id for seq_id, _ in seq_gp])  # sequence_id per sample\n    \n    # Convert X and y to numpy arrays\n    X = pad_sequences(X_list, maxlen=pad_len, padding='post', truncating='post', dtype='float32')\n    y = to_categorical(y_labels, num_classes=len(le.classes_))\n    \n    # Group-aware split\n    gkf = GroupKFold(n_splits=5)\n    for fold, (train_idx, val_idx) in enumerate(gkf.split(X, y_labels, groups=groups)):\n        X_tr, X_val = X[train_idx], X[val_idx]\n        y_tr, y_val = y[train_idx], y[val_idx]\n        print(f\"✅ Fold {fold}: Train size = {len(train_idx)}, Val size = {len(val_idx)}\")\n        break  # Use only the first fold for now\n\n    \n\n    # class weights\n    cw_vals = compute_class_weight('balanced', classes=np.arange(len(le.classes_)), y=y_list)\n    class_weight = dict(enumerate(cw_vals))\n\n    # model\n    model = build_two_branch_model(pad_len, len(imu_cols), len(tof_cols), len(le.classes_), wd=WD)\n    steps = len(X_tr)//BATCH_SIZE\n    lr_sched = tf.keras.optimizers.schedules.CosineDecayRestarts(LR_INIT, first_decay_steps=5*steps)\n    model.compile(optimizer=Adam(lr_sched),\n                  loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n                  metrics=['accuracy'])\n\n    train_gen = MixupGenerator(X_tr, y_tr, batch_size=BATCH_SIZE, alpha=MIXUP_ALPHA)\n    cb = EarlyStopping(patience=PATIENCE, restore_best_weights=True, verbose=1)\n    model.fit(train_gen, epochs=EPOCHS, validation_data=(X_val, y_val),\n              class_weight=class_weight, callbacks=[cb], verbose=1)\n\n    model.save(EXPORT_DIR / \"gesture_two_branch_mixup.h5\")\n    print(\"✔ Training done – artefacts saved in\", EXPORT_DIR)\n\n    # quick metric\n    from cmi_2025_metric_copy_for_import import CompetitionMetric\n    preds = model.predict(X_val).argmax(1)\n    true  = y_val.argmax(1)\n    h_f1 = CompetitionMetric().calculate_hierarchical_f1(\n        pd.DataFrame({'gesture': le.classes_[true]}),\n        pd.DataFrame({'gesture': le.classes_[preds]}))\n    print(\"Hold‑out H‑F1 =\", round(h_f1, 4))\n\nelse:\n    print(\"▶ INFERENCE MODE – loading artefacts from\", PRETRAINED_DIR)\n    feature_cols   = np.load(PRETRAINED_DIR / \"feature_cols.npy\", allow_pickle=True).tolist()\n    pad_len        = int(np.load(PRETRAINED_DIR / \"sequence_maxlen.npy\"))\n    scaler         = joblib.load(PRETRAINED_DIR / \"scaler.pkl\")\n    gesture_classes = np.load(PRETRAINED_DIR / \"gesture_classes.npy\", allow_pickle=True)\n\n    imu_cols = [c for c in feature_cols if not (c.startswith('thm_') or c.startswith('tof_'))]\n    tof_cols = [c for c in feature_cols if c.startswith('thm_') or c.startswith('tof_')]\n\n    custom_objs = {\n        'time_sum': time_sum,\n        'squeeze_last_axis': squeeze_last_axis,\n        'expand_last_axis': expand_last_axis,\n        'se_block': se_block,\n        'residual_se_cnn_block': residual_se_cnn_block,\n        'attention_layer': attention_layer,\n    }\n    model = load_model(PRETRAINED_DIR / \"gesture_two_branch_mixup.h5\",\n                       compile=False, custom_objects=custom_objs)\n    print(\"  model, scaler, pads loaded – ready for evaluation\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T13:35:33.750833Z","iopub.execute_input":"2025-06-09T13:35:33.75142Z","iopub.status.idle":"2025-06-09T13:43:20.388039Z","shell.execute_reply.started":"2025-06-09T13:35:33.751376Z","shell.execute_reply":"2025-06-09T13:43:20.387432Z"}},"outputs":[{"name":"stdout","text":"▶ TRAIN MODE – loading dataset …\n  IMU 7 | TOF/THM 325 | total 332 features\n✅ Fold 0: Train size = 6520, Val size = 1631\nEpoch 1/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 54ms/step - accuracy: 0.1302 - loss: 3.4831 - val_accuracy: 0.1704 - val_loss: 3.0436\nEpoch 2/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.2505 - loss: 2.9292 - val_accuracy: 0.3335 - val_loss: 2.6248\nEpoch 3/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.3064 - loss: 2.7519 - val_accuracy: 0.4372 - val_loss: 2.3840\nEpoch 4/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.3576 - loss: 2.5537 - val_accuracy: 0.4592 - val_loss: 2.2970\nEpoch 5/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.3683 - loss: 2.6024 - val_accuracy: 0.4384 - val_loss: 2.3012\nEpoch 6/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.3739 - loss: 2.5414 - val_accuracy: 0.4470 - val_loss: 2.2715\nEpoch 7/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.3817 - loss: 2.5028 - val_accuracy: 0.4703 - val_loss: 2.1722\nEpoch 8/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.4201 - loss: 2.4450 - val_accuracy: 0.4838 - val_loss: 2.1009\nEpoch 9/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.4443 - loss: 2.4523 - val_accuracy: 0.5212 - val_loss: 2.0138\nEpoch 10/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.4617 - loss: 2.3304 - val_accuracy: 0.5310 - val_loss: 1.9858\nEpoch 11/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.4730 - loss: 2.3060 - val_accuracy: 0.5463 - val_loss: 1.9239\nEpoch 12/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.5117 - loss: 2.2351 - val_accuracy: 0.5635 - val_loss: 1.9002\nEpoch 13/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.5466 - loss: 2.1667 - val_accuracy: 0.5782 - val_loss: 1.8615\nEpoch 14/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.5433 - loss: 2.1023 - val_accuracy: 0.5843 - val_loss: 1.8525\nEpoch 15/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.5381 - loss: 2.1964 - val_accuracy: 0.5328 - val_loss: 1.9793\nEpoch 16/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.5124 - loss: 2.1721 - val_accuracy: 0.5120 - val_loss: 2.0052\nEpoch 17/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.4971 - loss: 2.2067 - val_accuracy: 0.4985 - val_loss: 2.0064\nEpoch 18/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.5319 - loss: 2.1230 - val_accuracy: 0.5555 - val_loss: 1.8800\nEpoch 19/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.5325 - loss: 2.1477 - val_accuracy: 0.5837 - val_loss: 1.7783\nEpoch 20/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.5707 - loss: 2.0825 - val_accuracy: 0.5874 - val_loss: 1.7722\nEpoch 21/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.5800 - loss: 2.0392 - val_accuracy: 0.5978 - val_loss: 1.7393\nEpoch 22/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.5812 - loss: 2.0286 - val_accuracy: 0.6235 - val_loss: 1.6809\nEpoch 23/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.5874 - loss: 1.9787 - val_accuracy: 0.6223 - val_loss: 1.6443\nEpoch 24/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.6291 - loss: 1.8546 - val_accuracy: 0.6039 - val_loss: 1.6838\nEpoch 25/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.6174 - loss: 1.9750 - val_accuracy: 0.6321 - val_loss: 1.6289\nEpoch 26/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.6423 - loss: 1.9483 - val_accuracy: 0.6340 - val_loss: 1.6247\nEpoch 27/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.6666 - loss: 1.8091 - val_accuracy: 0.6468 - val_loss: 1.5848\nEpoch 28/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.6656 - loss: 1.8280 - val_accuracy: 0.6524 - val_loss: 1.5690\nEpoch 29/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.6914 - loss: 1.8338 - val_accuracy: 0.6646 - val_loss: 1.5488\nEpoch 30/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.6788 - loss: 1.8120 - val_accuracy: 0.6720 - val_loss: 1.5272\nEpoch 31/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.6659 - loss: 1.8863 - val_accuracy: 0.6824 - val_loss: 1.5168\nEpoch 32/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.6967 - loss: 1.7962 - val_accuracy: 0.6861 - val_loss: 1.5093\nEpoch 33/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.7043 - loss: 1.7848 - val_accuracy: 0.6953 - val_loss: 1.5059\nEpoch 34/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.6870 - loss: 1.8227 - val_accuracy: 0.6934 - val_loss: 1.5040\nEpoch 35/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.6992 - loss: 1.8364 - val_accuracy: 0.6082 - val_loss: 1.6904\nEpoch 36/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.5999 - loss: 2.0594 - val_accuracy: 0.6058 - val_loss: 1.6745\nEpoch 37/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.6289 - loss: 1.8608 - val_accuracy: 0.5874 - val_loss: 1.7179\nEpoch 38/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.6074 - loss: 1.9370 - val_accuracy: 0.6438 - val_loss: 1.6055\nEpoch 39/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.6155 - loss: 1.9804 - val_accuracy: 0.6248 - val_loss: 1.6326\nEpoch 40/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.6504 - loss: 1.8172 - val_accuracy: 0.6370 - val_loss: 1.5832\nEpoch 41/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.6477 - loss: 1.8478 - val_accuracy: 0.6278 - val_loss: 1.6099\nEpoch 42/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.6451 - loss: 1.8544 - val_accuracy: 0.6475 - val_loss: 1.5963\nEpoch 43/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.6830 - loss: 1.7901 - val_accuracy: 0.6315 - val_loss: 1.5854\nEpoch 44/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.6852 - loss: 1.7947 - val_accuracy: 0.6665 - val_loss: 1.5593\nEpoch 45/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.6874 - loss: 1.7155 - val_accuracy: 0.6426 - val_loss: 1.5998\nEpoch 46/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.6724 - loss: 1.8358 - val_accuracy: 0.6438 - val_loss: 1.6139\nEpoch 47/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.6759 - loss: 1.8052 - val_accuracy: 0.6701 - val_loss: 1.5191\nEpoch 48/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.6897 - loss: 1.7683 - val_accuracy: 0.6591 - val_loss: 1.5099\nEpoch 49/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.6601 - loss: 1.8460 - val_accuracy: 0.6750 - val_loss: 1.5272\nEpoch 50/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.6883 - loss: 1.8119 - val_accuracy: 0.6977 - val_loss: 1.4873\nEpoch 51/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.7113 - loss: 1.6675 - val_accuracy: 0.6824 - val_loss: 1.4887\nEpoch 52/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7327 - loss: 1.7193 - val_accuracy: 0.6787 - val_loss: 1.4917\nEpoch 53/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7313 - loss: 1.6833 - val_accuracy: 0.6775 - val_loss: 1.4824\nEpoch 54/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.7397 - loss: 1.6926 - val_accuracy: 0.6800 - val_loss: 1.4807\nEpoch 55/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.7532 - loss: 1.5748 - val_accuracy: 0.6800 - val_loss: 1.4901\nEpoch 56/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7368 - loss: 1.6750 - val_accuracy: 0.6849 - val_loss: 1.4510\nEpoch 57/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7753 - loss: 1.6236 - val_accuracy: 0.6879 - val_loss: 1.4685\nEpoch 58/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7451 - loss: 1.6269 - val_accuracy: 0.7039 - val_loss: 1.4399\nEpoch 59/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7385 - loss: 1.7260 - val_accuracy: 0.7020 - val_loss: 1.4352\nEpoch 60/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7919 - loss: 1.5467 - val_accuracy: 0.7082 - val_loss: 1.4141\nEpoch 61/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7890 - loss: 1.4963 - val_accuracy: 0.7014 - val_loss: 1.4121\nEpoch 62/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.8003 - loss: 1.5527 - val_accuracy: 0.7045 - val_loss: 1.4013\nEpoch 63/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.7935 - loss: 1.6034 - val_accuracy: 0.7137 - val_loss: 1.4096\nEpoch 64/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7808 - loss: 1.5431 - val_accuracy: 0.7088 - val_loss: 1.4095\nEpoch 65/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8055 - loss: 1.4829 - val_accuracy: 0.7137 - val_loss: 1.4076\nEpoch 66/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.7982 - loss: 1.5527 - val_accuracy: 0.7131 - val_loss: 1.4002\nEpoch 67/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7967 - loss: 1.5340 - val_accuracy: 0.7137 - val_loss: 1.4019\nEpoch 68/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.8263 - loss: 1.4172 - val_accuracy: 0.7229 - val_loss: 1.3916\nEpoch 69/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.8290 - loss: 1.4784 - val_accuracy: 0.7204 - val_loss: 1.3805\nEpoch 70/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.8333 - loss: 1.4369 - val_accuracy: 0.7174 - val_loss: 1.3845\nEpoch 71/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8060 - loss: 1.4976 - val_accuracy: 0.7174 - val_loss: 1.3833\nEpoch 72/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8331 - loss: 1.4254 - val_accuracy: 0.7167 - val_loss: 1.3811\nEpoch 73/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8537 - loss: 1.4716 - val_accuracy: 0.7149 - val_loss: 1.3832\nEpoch 74/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.8215 - loss: 1.5204 - val_accuracy: 0.7161 - val_loss: 1.3836\nEpoch 75/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.7653 - loss: 1.5574 - val_accuracy: 0.6352 - val_loss: 1.5976\nEpoch 76/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7215 - loss: 1.7433 - val_accuracy: 0.6597 - val_loss: 1.5445\nEpoch 77/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7129 - loss: 1.6496 - val_accuracy: 0.6646 - val_loss: 1.5158\nEpoch 78/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7161 - loss: 1.6537 - val_accuracy: 0.6468 - val_loss: 1.5828\nEpoch 79/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7141 - loss: 1.6813 - val_accuracy: 0.6885 - val_loss: 1.4738\nEpoch 80/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7279 - loss: 1.6968 - val_accuracy: 0.6591 - val_loss: 1.5439\nEpoch 81/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.6987 - loss: 1.7779 - val_accuracy: 0.6842 - val_loss: 1.5185\nEpoch 82/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7310 - loss: 1.7023 - val_accuracy: 0.6750 - val_loss: 1.5308\nEpoch 83/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7450 - loss: 1.6431 - val_accuracy: 0.6757 - val_loss: 1.5027\nEpoch 84/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7638 - loss: 1.5988 - val_accuracy: 0.6879 - val_loss: 1.4969\nEpoch 85/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7497 - loss: 1.6779 - val_accuracy: 0.6775 - val_loss: 1.5062\nEpoch 86/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.7867 - loss: 1.5537 - val_accuracy: 0.6781 - val_loss: 1.5208\nEpoch 87/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.7498 - loss: 1.6133 - val_accuracy: 0.6714 - val_loss: 1.5288\nEpoch 88/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7439 - loss: 1.6485 - val_accuracy: 0.6738 - val_loss: 1.4970\nEpoch 89/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7732 - loss: 1.6016 - val_accuracy: 0.6855 - val_loss: 1.5203\nEpoch 90/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7762 - loss: 1.4955 - val_accuracy: 0.6757 - val_loss: 1.5163\nEpoch 91/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7179 - loss: 1.7861 - val_accuracy: 0.6953 - val_loss: 1.5002\nEpoch 92/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7713 - loss: 1.5818 - val_accuracy: 0.6842 - val_loss: 1.4943\nEpoch 93/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7550 - loss: 1.6576 - val_accuracy: 0.6039 - val_loss: 1.7121\nEpoch 94/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7767 - loss: 1.5812 - val_accuracy: 0.6701 - val_loss: 1.5393\nEpoch 95/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7884 - loss: 1.5763 - val_accuracy: 0.6800 - val_loss: 1.4991\nEpoch 96/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7787 - loss: 1.6110 - val_accuracy: 0.6996 - val_loss: 1.4849\nEpoch 97/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7771 - loss: 1.6436 - val_accuracy: 0.7014 - val_loss: 1.4636\nEpoch 98/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7750 - loss: 1.5722 - val_accuracy: 0.7094 - val_loss: 1.4757\nEpoch 99/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7745 - loss: 1.5893 - val_accuracy: 0.7002 - val_loss: 1.4746\nEpoch 100/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7468 - loss: 1.7034 - val_accuracy: 0.6990 - val_loss: 1.4854\nEpoch 101/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.7578 - loss: 1.6336 - val_accuracy: 0.7045 - val_loss: 1.4723\nEpoch 102/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8049 - loss: 1.5920 - val_accuracy: 0.6996 - val_loss: 1.4677\nEpoch 103/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7912 - loss: 1.5767 - val_accuracy: 0.7032 - val_loss: 1.4839\nEpoch 104/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7745 - loss: 1.5793 - val_accuracy: 0.7106 - val_loss: 1.4672\nEpoch 105/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8331 - loss: 1.4479 - val_accuracy: 0.6891 - val_loss: 1.5165\nEpoch 106/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7773 - loss: 1.6415 - val_accuracy: 0.7235 - val_loss: 1.4294\nEpoch 107/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8263 - loss: 1.4897 - val_accuracy: 0.7063 - val_loss: 1.4652\nEpoch 108/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8081 - loss: 1.5512 - val_accuracy: 0.7082 - val_loss: 1.4616\nEpoch 109/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8085 - loss: 1.5350 - val_accuracy: 0.7137 - val_loss: 1.4511\nEpoch 109: early stopping\nRestoring model weights from the end of the best epoch: 69.\n✔ Training done – artefacts saved in .\n\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step\nHold‑out H‑F1 = 0.8304\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"## Predicting","metadata":{}},{"cell_type":"code","source":"# make sure gesture_classes exists in both modes\nif TRAIN:\n    gesture_classes = le.classes_\n\n\ndef predict(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:\n    global gesture_classes\n    if gesture_classes is None:\n        gesture_classes = np.load(PRETRAINED_DIR / \"gesture_classes.npy\", allow_pickle=True)\n\n    df_seq = sequence.to_pandas()\n    mat = preprocess_sequence(df_seq, feature_cols, scaler)\n    pad = pad_sequences([mat], maxlen=pad_len, padding='post', truncating='post', dtype='float32')\n    idx = int(model.predict(pad, verbose=0).argmax(1)[0])\n    return str(gesture_classes[idx])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T13:44:33.887139Z","iopub.execute_input":"2025-06-09T13:44:33.887774Z","iopub.status.idle":"2025-06-09T13:44:33.893151Z","shell.execute_reply.started":"2025-06-09T13:44:33.887749Z","shell.execute_reply":"2025-06-09T13:44:33.892325Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"## Integration with Kaggle Evaluation","metadata":{}},{"cell_type":"code","source":"import kaggle_evaluation.cmi_inference_server\ninference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(\n        data_paths=(\n            '/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv',\n            '/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv',\n        )\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T13:44:34.686941Z","iopub.execute_input":"2025-06-09T13:44:34.687442Z","iopub.status.idle":"2025-06-09T13:44:35.806826Z","shell.execute_reply.started":"2025-06-09T13:44:34.687416Z","shell.execute_reply":"2025-06-09T13:44:35.805995Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"## Acknowledgement:\n  [https://www.kaggle.com/code/vonmainstein/imu-tof](https://www.kaggle.com/code/vonmainstein/imu-tof)\n\n  All credits go to this notebook. Have tried some played with some parameters to get better score. Hope this is useful.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}