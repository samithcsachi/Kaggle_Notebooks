{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/samithsachidanandan/attention-is-all-you-need-implementation?scriptVersionId=247486280\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"6856f3ad","metadata":{"execution":{"iopub.execute_input":"2025-06-26T12:07:44.618649Z","iopub.status.busy":"2025-06-26T12:07:44.618325Z","iopub.status.idle":"2025-06-26T12:07:49.953739Z","shell.execute_reply":"2025-06-26T12:07:49.952978Z"},"papermill":{"duration":5.341089,"end_time":"2025-06-26T12:07:49.955348","exception":false,"start_time":"2025-06-26T12:07:44.614259","status":"completed"},"tags":[]},"outputs":[],"source":["import torch \n","import torch.nn as nn "]},{"cell_type":"code","execution_count":2,"id":"b9093f84","metadata":{"execution":{"iopub.execute_input":"2025-06-26T12:07:49.962454Z","iopub.status.busy":"2025-06-26T12:07:49.96202Z","iopub.status.idle":"2025-06-26T12:07:49.971538Z","shell.execute_reply":"2025-06-26T12:07:49.970647Z"},"papermill":{"duration":0.014379,"end_time":"2025-06-26T12:07:49.972797","exception":false,"start_time":"2025-06-26T12:07:49.958418","status":"completed"},"tags":[]},"outputs":[],"source":["class SelfAttention(nn.Module):\n","    def __init__(self, embed_size, heads):\n","        super(SelfAttention, self).__init__()\n","        self.embed_size = embed_size\n","        self.heads = heads \n","        self.head_dim = embed_size // heads\n","\n","        assert (self.head_dim * heads == embed_size), \"Embed size needs to be div by heads\"\n","        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n","        self.keys = nn.Linear(self.head_dim, self.head_dim, bias=False)\n","        self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n","        self.fc_out = nn.Linear(heads*self.head_dim, embed_size)\n","\n","    def forward(self, values, keys, query, mask):\n","        N =query.shape[0]\n","        value_len, key_len, query_len =  values.shape[1], keys.shape[1], query.shape[1]\n","\n","        # Split embedding into self,heads pieces\n","        values = values.reshape(N, value_len, self.heads, self.head_dim)\n","        keys = keys.reshape(N, key_len,self.heads, self.head_dim )\n","        queries = query.reshape(N, query_len,self.heads, self.head_dim) \n","        \n","        values = self.values(values)\n","        keys = self.keys(keys)\n","        queries = self.queries(queries)\n","        \n","\n","        energy = torch.einsum(\"nqhd,nkhd->nhqk\",[queries,keys])\n","        # query shape : (N, query_len, heads, heads_dim)\n","        # keys shape: (N,key_len, heads, heads_dim )\n","        # energy shape : (N, heads, query_len, key_len)\n","\n","        if mask is not None:\n","            energy = energy.masked_fill(mask ==0, float(\"-1e20\"))\n","\n","        attention = torch.softmax(energy / (self.embed_size **(1/2)), dim=3)\n","        out = torch.einsum(\"nhql,nlhd->nqhd\",[attention, values]).reshape(N, query_len, self.heads*self.head_dim)\n","        # attention shape: (N, heads, query_len, key_len)\n","        # value shape : (N, value_len, heads, heads_dim)\n","        # after einsum(N, query_len, heads, heads_dim) then flatten last two dimensions\n","\n","        out = self.fc_out(out)\n","        return out \n"]},{"cell_type":"code","execution_count":3,"id":"6474718d","metadata":{"execution":{"iopub.execute_input":"2025-06-26T12:07:49.978564Z","iopub.status.busy":"2025-06-26T12:07:49.978312Z","iopub.status.idle":"2025-06-26T12:07:49.984599Z","shell.execute_reply":"2025-06-26T12:07:49.983852Z"},"papermill":{"duration":0.010689,"end_time":"2025-06-26T12:07:49.985898","exception":false,"start_time":"2025-06-26T12:07:49.975209","status":"completed"},"tags":[]},"outputs":[],"source":["class TransformerBlock(nn.Module):\n","    def __init__(self, embed_size, heads, dropout, forward_expansion):\n","        super(TransformerBlock, self).__init__()\n","        self.attention = SelfAttention(embed_size,heads)\n","        self.norm1 = nn.LayerNorm(embed_size)\n","        self.norm2 = nn.LayerNorm(embed_size)\n","\n","        self.feed_forward = nn.Sequential(\n","            nn.Linear(embed_size, forward_expansion*embed_size),\n","            nn.ReLU(),\n","            nn.Linear(forward_expansion*embed_size, embed_size)\n","        )\n","        self.dropout = nn.Dropout(dropout)\n","\n","    \n","    def forward(self, value, key, query, mask):\n","        attention = self.attention(value, key, query, mask)\n","\n","        x = self.dropout(self.norm1(attention + query))\n","        forward = self.feed_forward(x)\n","        out = self.dropout(self.norm2(forward + x ))\n","        return out "]},{"cell_type":"code","execution_count":4,"id":"cce502e4","metadata":{"execution":{"iopub.execute_input":"2025-06-26T12:07:49.991802Z","iopub.status.busy":"2025-06-26T12:07:49.991542Z","iopub.status.idle":"2025-06-26T12:07:49.9985Z","shell.execute_reply":"2025-06-26T12:07:49.997785Z"},"papermill":{"duration":0.011377,"end_time":"2025-06-26T12:07:49.999729","exception":false,"start_time":"2025-06-26T12:07:49.988352","status":"completed"},"tags":[]},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(\n","        self, \n","        src_vocab_size,\n","        embed_size,\n","        num_layers,\n","        heads,\n","        device,\n","        forward_expansion,\n","        dropout,\n","        max_length,\n","    ):\n","        super(Encoder,self).__init__()\n","        self.embed_size = embed_size\n","        self.device = device\n","        self.word_embedding = nn.Embedding(src_vocab_size, embed_size)\n","        self.position_embedding = nn.Embedding(max_length, embed_size)\n","\n","        self.layers = nn.ModuleList(\n","            [\n","                TransformerBlock(\n","                    embed_size,\n","                    heads,\n","                    dropout=dropout,\n","                    forward_expansion=forward_expansion,\n","                    \n","                )\n","            \n","    \n","                \n","            for _ in range(num_layers)        ]\n","            \n","        )\n","        \n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, mask):\n","        N, seq_length =x.shape\n","        positions = torch.arange(0, seq_length).expand(N, seq_length).to(self.device)\n","\n","        out = self.dropout(self.word_embedding(x) + self.position_embedding(positions))\n","\n","        for layer in self.layers:\n","            out = layer(out, out, out, mask)\n","\n","        return out \n","        \n","        "]},{"cell_type":"code","execution_count":5,"id":"35b9e488","metadata":{"execution":{"iopub.execute_input":"2025-06-26T12:07:50.005732Z","iopub.status.busy":"2025-06-26T12:07:50.005442Z","iopub.status.idle":"2025-06-26T12:07:50.011093Z","shell.execute_reply":"2025-06-26T12:07:50.01044Z"},"papermill":{"duration":0.010138,"end_time":"2025-06-26T12:07:50.012519","exception":false,"start_time":"2025-06-26T12:07:50.002381","status":"completed"},"tags":[]},"outputs":[],"source":["class DecoderBlock(nn.Module):\n","    def __init__(self, embed_size, heads, forward_expansion, dropout, device):\n","        super(DecoderBlock, self).__init__()\n","        self.attention = SelfAttention(embed_size, heads)\n","        self.norm = nn.LayerNorm(embed_size)\n","        self.transformer_block = TransformerBlock(\n","            embed_size, heads, dropout, forward_expansion\n","        )\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, value, key,  src_mask, trg_mask):\n","        attention = self.attention(x, x, x, trg_mask)\n","        query = self.dropout(self.norm(attention + x ))\n","        out = self.transformer_block(value, key, query, src_mask)\n","        return out\n","      \n","        "]},{"cell_type":"code","execution_count":6,"id":"235d0d81","metadata":{"execution":{"iopub.execute_input":"2025-06-26T12:07:50.018185Z","iopub.status.busy":"2025-06-26T12:07:50.017918Z","iopub.status.idle":"2025-06-26T12:07:50.025168Z","shell.execute_reply":"2025-06-26T12:07:50.024467Z"},"papermill":{"duration":0.011716,"end_time":"2025-06-26T12:07:50.026667","exception":false,"start_time":"2025-06-26T12:07:50.014951","status":"completed"},"tags":[]},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self,\n","                 trg_vocab_size,\n","                 embed_size,\n","                 num_layers, \n","                 heads,\n","                 forward_expansion,\n","                 dropout,\n","                 device, \n","                 max_length):\n","        super(Decoder, self).__init__()\n","        self.device = device\n","\n","        self.word_embedding = nn.Embedding(trg_vocab_size, embed_size)\n","        self.position_embedding = nn.Embedding(max_length, embed_size)\n","\n","        self.layers = nn.ModuleList([\n","            DecoderBlock(embed_size, heads, forward_expansion, dropout, device)\n","            for _ in range(num_layers)\n","        ])\n","\n","        self.fc_out = nn.Linear(embed_size, trg_vocab_size)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, enc_out, src_mask, trg_mask):\n","        N, seq_length = x.shape\n","        positions = torch.arange(0, seq_length).expand(N, seq_length).to(self.device)\n","\n","        x = self.dropout(self.word_embedding(x) + self.position_embedding(positions))\n","\n","        for layer in self.layers:\n","            x = layer(x, enc_out, enc_out, src_mask, trg_mask)\n","\n","        out = self.fc_out(x)\n","        return out\n"]},{"cell_type":"code","execution_count":7,"id":"01c5688b","metadata":{"execution":{"iopub.execute_input":"2025-06-26T12:07:50.032636Z","iopub.status.busy":"2025-06-26T12:07:50.032345Z","iopub.status.idle":"2025-06-26T12:07:50.040522Z","shell.execute_reply":"2025-06-26T12:07:50.039438Z"},"papermill":{"duration":0.012962,"end_time":"2025-06-26T12:07:50.041924","exception":false,"start_time":"2025-06-26T12:07:50.028962","status":"completed"},"tags":[]},"outputs":[],"source":["class Transformer(nn.Module):\n","    def __init__(\n","        self, \n","        src_vocab_size, \n","        trg_vocab_size,\n","        src_pad_idx,\n","        trg_pad_idx,\n","        embed_size=256,\n","        num_layers=6,\n","        forward_expansion=4,\n","        heads=8,\n","        dropout=0,\n","        device=\"cpu\",\n","        max_length=100,\n","            \n","    ):\n","        super(Transformer, self).__init__()\n","        self.device = device\n","        self.encoder = Encoder(\n","            src_vocab_size,\n","            embed_size, \n","            num_layers,\n","            heads, \n","            device,\n","            forward_expansion,\n","            dropout,\n","            max_length\n","            \n","        )\n","\n","        self.decoder = Decoder(\n","            trg_vocab_size,\n","            embed_size, \n","            num_layers,\n","            heads, \n","            forward_expansion,\n","            dropout,\n","            device,\n","            max_length\n","            \n","        )\n","\n","        self.src_pad_idx = src_pad_idx\n","        self.trg_pad_idx = trg_pad_idx\n","        self.device = device \n","\n","    def make_src_mask(self, src):\n","        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n","        # (N, 1, 1, src_len)\n","        return src_mask.to(self.device)\n","\n","    def make_trg_mask(self, trg):\n","        N, trg_len = trg.shape\n","        trg_mask = torch.tril(torch.ones((trg_len, trg_len))).expand(\n","            N, 1, trg_len, trg_len\n","            \n","        )\n","        return trg_mask.to(self.device)\n","\n","    def forward(self, src, trg):\n","        src_mask = self.make_src_mask(src)\n","        trg_mask = self.make_trg_mask(trg)\n","        enc_src = self.encoder(src, src_mask)\n","        out = self.decoder(trg, enc_src, src_mask, trg_mask)\n","        return out \n","        "]},{"cell_type":"code","execution_count":8,"id":"08299f5f","metadata":{"execution":{"iopub.execute_input":"2025-06-26T12:07:50.048092Z","iopub.status.busy":"2025-06-26T12:07:50.047791Z","iopub.status.idle":"2025-06-26T12:07:50.420182Z","shell.execute_reply":"2025-06-26T12:07:50.419309Z"},"papermill":{"duration":0.3773,"end_time":"2025-06-26T12:07:50.421811","exception":false,"start_time":"2025-06-26T12:07:50.044511","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Output shape: torch.Size([2, 8, 10])\n"]}],"source":["if __name__ == \"__main__\":\n","    device = torch.device(\"cpu\")\n","\n","    \n","    x = torch.tensor([\n","        [1, 5, 6, 4, 3, 9, 5, 2, 0],\n","        [1, 8, 7, 3, 4, 5, 6, 7, 2]\n","    ], dtype=torch.long).to(device)\n","\n","    trg = torch.tensor([\n","        [1, 7, 4, 3, 5, 9, 2, 0, 0],\n","        [1, 5, 6, 2, 4, 7, 6, 2, 0]\n","    ], dtype=torch.long).to(device)\n","\n","    src_pad_idx = 0\n","    trg_pad_idx = 0\n","    src_vocab_size = 10\n","    trg_vocab_size = 10\n","\n","    model = Transformer(src_vocab_size, trg_vocab_size, src_pad_idx, trg_pad_idx).to(device)\n","\n","    out = model(x, trg[:, :-1]) \n","    print(\"Output shape:\", out.shape)  "]},{"cell_type":"code","execution_count":null,"id":"27a579c1","metadata":{"papermill":{"duration":0.002209,"end_time":"2025-06-26T12:07:50.426557","exception":false,"start_time":"2025-06-26T12:07:50.424348","status":"completed"},"tags":[]},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"papermill":{"default_parameters":{},"duration":13.128973,"end_time":"2025-06-26T12:07:53.07091","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-06-26T12:07:39.941937","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}